{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8de690ce-49d6-4387-b242-fe36280ca9dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Début à:** Friday 03 June 2022, 11:31:14  \n",
       "**Hostname:** insa-11357 (Linux)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<p style=\"text-align: center\"><img width=\"800px\" src=\"./svg/logoBegin.svg\" style=\"margin-left:auto; margin-right:auto\"/></p>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Démarrage de l'exercice 3\n",
    "import visualID as vID\n",
    "from visualID import color\n",
    "vID.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2f60c2-8759-4019-8dea-b692e73eaee6",
   "metadata": {},
   "source": [
    "### Apprentissage supervisé (*supervised Machine Learning*) appliqué à la classification. Suggestion de petite(s) application(s) en autonomie. Corrigé"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02aa070-ddf4-4bb4-bb26-5043ee7ca53f",
   "metadata": {},
   "source": [
    "#### Importation des librairies utiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6568ba3-8b12-4725-a890-132a9de260b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib as mp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7334ed83-f6aa-4f7e-b6a1-7e49b8b9da66",
   "metadata": {},
   "source": [
    "#### a. Lecture de la base de données qui ont été adaptées au problème"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef2fe4da-b86e-4c95-8f97-84f8c0f56215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dfi. Structure (shape) :(150, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "      <th>setosa</th>\n",
       "      <th>versicolor</th>\n",
       "      <th>virginica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>virginica</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width    species  setosa  \\\n",
       "0             5.1          3.5           1.4          0.2     setosa     1.0   \n",
       "1             4.9          3.0           1.4          0.2     setosa     1.0   \n",
       "2             4.7          3.2           1.3          0.2     setosa     1.0   \n",
       "3             4.6          3.1           1.5          0.2     setosa     1.0   \n",
       "4             5.0          3.6           1.4          0.2     setosa     1.0   \n",
       "..            ...          ...           ...          ...        ...     ...   \n",
       "145           6.7          3.0           5.2          2.3  virginica     0.0   \n",
       "146           6.3          2.5           5.0          1.9  virginica     0.0   \n",
       "147           6.5          3.0           5.2          2.0  virginica     0.0   \n",
       "148           6.2          3.4           5.4          2.3  virginica     0.0   \n",
       "149           5.9          3.0           5.1          1.8  virginica     0.0   \n",
       "\n",
       "     versicolor  virginica  \n",
       "0           0.0        0.0  \n",
       "1           0.0        0.0  \n",
       "2           0.0        0.0  \n",
       "3           0.0        0.0  \n",
       "4           0.0        0.0  \n",
       "..          ...        ...  \n",
       "145         0.0        1.0  \n",
       "146         0.0        1.0  \n",
       "147         0.0        1.0  \n",
       "148         0.0        1.0  \n",
       "149         0.0        1.0  \n",
       "\n",
       "[150 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfi=pd.read_csv('./iris-data/iris_ohe.csv', sep=\"\\t\") #les colonnes sont séparées par des tabulations\n",
    "print(f\"Dfi. Structure (shape) :{dfi.shape}\")\n",
    "display(dfi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139cdc56-49f8-4775-abb6-1e9b2ff1b292",
   "metadata": {},
   "source": [
    "#### b. Séparation des données en deux sous-ensembles d'apprentissage et de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0470f71-6f34-4ccf-9e56-836928e32004",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train :  (120, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.6</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>7.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.6</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width\n",
       "113           5.7          2.5           5.0          2.0\n",
       "79            5.7          2.6           3.5          1.0\n",
       "31            5.4          3.4           1.5          0.4\n",
       "117           7.7          3.8           6.7          2.2\n",
       "55            5.7          2.8           4.5          1.3\n",
       "..            ...          ...           ...          ...\n",
       "20            5.4          3.4           1.7          0.2\n",
       "109           7.2          3.6           6.1          2.5\n",
       "125           7.2          3.2           6.0          1.8\n",
       "116           6.5          3.0           5.5          1.8\n",
       "123           6.3          2.7           4.9          1.8\n",
       "\n",
       "[120 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train :  (120, 3) y_train_species :  (120, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>setosa</th>\n",
       "      <th>versicolor</th>\n",
       "      <th>virginica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     setosa  versicolor  virginica\n",
       "113     0.0         0.0        1.0\n",
       "79      0.0         1.0        0.0\n",
       "31      1.0         0.0        0.0\n",
       "117     0.0         0.0        1.0\n",
       "55      0.0         1.0        0.0\n",
       "..      ...         ...        ...\n",
       "20      1.0         0.0        0.0\n",
       "109     0.0         0.0        1.0\n",
       "125     0.0         0.0        1.0\n",
       "116     0.0         0.0        1.0\n",
       "123     0.0         0.0        1.0\n",
       "\n",
       "[120 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        species\n",
       "113   virginica\n",
       "79   versicolor\n",
       "31       setosa\n",
       "117   virginica\n",
       "55   versicolor\n",
       "..          ...\n",
       "20       setosa\n",
       "109   virginica\n",
       "125   virginica\n",
       "116   virginica\n",
       "123   virginica\n",
       "\n",
       "[120 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_train = dfi.sample(frac=0.8, axis='index') # on sélectionne au hasard 80% de l'échantillon\n",
    "data_test  = dfi.drop(data_train.index) # on sélectionne le reste\n",
    "\n",
    "x_train = data_train[['sepal_length','sepal_width','petal_length','petal_width']]\n",
    "y_train = data_train[['setosa','versicolor','virginica']]\n",
    "y_train_species = data_train[['species']] #sera utile à la fin pour comparer la prédiction et l'espèce réelle\n",
    "\n",
    "x_test  = data_test[['sepal_length','sepal_width','petal_length','petal_width']]\n",
    "y_test  = data_test[['setosa','versicolor','virginica']]\n",
    "y_test_species = data_test[['species']] #sera utile à la fin pour comparer la prédiction et l'espèce réelle\n",
    "\n",
    "print('x_train : ',x_train.shape)\n",
    "display(x_train)\n",
    "print('y_train : ',y_train.shape,'y_train_species : ',y_train_species.shape)\n",
    "display(y_train, y_train_species)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94b4f9b-46d6-4988-a3f3-ab75734b6ffa",
   "metadata": {},
   "source": [
    "#### c. Adaptation des données à la régression logistique par le réseau de neurones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70779f6b-4820-427f-a2ce-96ac775809a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_7d9cd\">\n",
       "  <caption>Training set après normalisation (avec scikit-learn):</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_7d9cd_level0_col0\" class=\"col_heading level0 col0\" >sepal_length</th>\n",
       "      <th id=\"T_7d9cd_level0_col1\" class=\"col_heading level0 col1\" >sepal_width</th>\n",
       "      <th id=\"T_7d9cd_level0_col2\" class=\"col_heading level0 col2\" >petal_length</th>\n",
       "      <th id=\"T_7d9cd_level0_col3\" class=\"col_heading level0 col3\" >petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_7d9cd_level0_row0\" class=\"row_heading level0 row0\" >count</th>\n",
       "      <td id=\"T_7d9cd_row0_col0\" class=\"data row0 col0\" >120.00</td>\n",
       "      <td id=\"T_7d9cd_row0_col1\" class=\"data row0 col1\" >120.00</td>\n",
       "      <td id=\"T_7d9cd_row0_col2\" class=\"data row0 col2\" >120.00</td>\n",
       "      <td id=\"T_7d9cd_row0_col3\" class=\"data row0 col3\" >120.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7d9cd_level0_row1\" class=\"row_heading level0 row1\" >mean</th>\n",
       "      <td id=\"T_7d9cd_row1_col0\" class=\"data row1 col0\" >0.00</td>\n",
       "      <td id=\"T_7d9cd_row1_col1\" class=\"data row1 col1\" >0.00</td>\n",
       "      <td id=\"T_7d9cd_row1_col2\" class=\"data row1 col2\" >-0.00</td>\n",
       "      <td id=\"T_7d9cd_row1_col3\" class=\"data row1 col3\" >-0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7d9cd_level0_row2\" class=\"row_heading level0 row2\" >std</th>\n",
       "      <td id=\"T_7d9cd_row2_col0\" class=\"data row2 col0\" >1.00</td>\n",
       "      <td id=\"T_7d9cd_row2_col1\" class=\"data row2 col1\" >1.00</td>\n",
       "      <td id=\"T_7d9cd_row2_col2\" class=\"data row2 col2\" >1.00</td>\n",
       "      <td id=\"T_7d9cd_row2_col3\" class=\"data row2 col3\" >1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7d9cd_level0_row3\" class=\"row_heading level0 row3\" >min</th>\n",
       "      <td id=\"T_7d9cd_row3_col0\" class=\"data row3 col0\" >-1.80</td>\n",
       "      <td id=\"T_7d9cd_row3_col1\" class=\"data row3 col1\" >-2.43</td>\n",
       "      <td id=\"T_7d9cd_row3_col2\" class=\"data row3 col2\" >-1.51</td>\n",
       "      <td id=\"T_7d9cd_row3_col3\" class=\"data row3 col3\" >-1.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7d9cd_level0_row4\" class=\"row_heading level0 row4\" >25%</th>\n",
       "      <td id=\"T_7d9cd_row4_col0\" class=\"data row4 col0\" >-0.86</td>\n",
       "      <td id=\"T_7d9cd_row4_col1\" class=\"data row4 col1\" >-0.63</td>\n",
       "      <td id=\"T_7d9cd_row4_col2\" class=\"data row4 col2\" >-1.24</td>\n",
       "      <td id=\"T_7d9cd_row4_col3\" class=\"data row4 col3\" >-1.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7d9cd_level0_row5\" class=\"row_heading level0 row5\" >50%</th>\n",
       "      <td id=\"T_7d9cd_row5_col0\" class=\"data row5 col0\" >-0.16</td>\n",
       "      <td id=\"T_7d9cd_row5_col1\" class=\"data row5 col1\" >-0.18</td>\n",
       "      <td id=\"T_7d9cd_row5_col2\" class=\"data row5 col2\" >0.32</td>\n",
       "      <td id=\"T_7d9cd_row5_col3\" class=\"data row5 col3\" >0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7d9cd_level0_row6\" class=\"row_heading level0 row6\" >75%</th>\n",
       "      <td id=\"T_7d9cd_row6_col0\" class=\"data row6 col0\" >0.66</td>\n",
       "      <td id=\"T_7d9cd_row6_col1\" class=\"data row6 col1\" >0.72</td>\n",
       "      <td id=\"T_7d9cd_row6_col2\" class=\"data row6 col2\" >0.76</td>\n",
       "      <td id=\"T_7d9cd_row6_col3\" class=\"data row6 col3\" >0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7d9cd_level0_row7\" class=\"row_heading level0 row7\" >max</th>\n",
       "      <td id=\"T_7d9cd_row7_col0\" class=\"data row7 col0\" >2.43</td>\n",
       "      <td id=\"T_7d9cd_row7_col1\" class=\"data row7 col1\" >2.97</td>\n",
       "      <td id=\"T_7d9cd_row7_col2\" class=\"data row7 col2\" >1.76</td>\n",
       "      <td id=\"T_7d9cd_row7_col3\" class=\"data row7 col3\" >1.70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f62170aac70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_a6350\">\n",
       "  <caption>Test set after après normalisation (avec scikit-learn):</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_a6350_level0_col0\" class=\"col_heading level0 col0\" >sepal_length</th>\n",
       "      <th id=\"T_a6350_level0_col1\" class=\"col_heading level0 col1\" >sepal_width</th>\n",
       "      <th id=\"T_a6350_level0_col2\" class=\"col_heading level0 col2\" >petal_length</th>\n",
       "      <th id=\"T_a6350_level0_col3\" class=\"col_heading level0 col3\" >petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_a6350_level0_row0\" class=\"row_heading level0 row0\" >count</th>\n",
       "      <td id=\"T_a6350_row0_col0\" class=\"data row0 col0\" >30.00</td>\n",
       "      <td id=\"T_a6350_row0_col1\" class=\"data row0 col1\" >30.00</td>\n",
       "      <td id=\"T_a6350_row0_col2\" class=\"data row0 col2\" >30.00</td>\n",
       "      <td id=\"T_a6350_row0_col3\" class=\"data row0 col3\" >30.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a6350_level0_row1\" class=\"row_heading level0 row1\" >mean</th>\n",
       "      <td id=\"T_a6350_row1_col0\" class=\"data row1 col0\" >0.05</td>\n",
       "      <td id=\"T_a6350_row1_col1\" class=\"data row1 col1\" >-0.28</td>\n",
       "      <td id=\"T_a6350_row1_col2\" class=\"data row1 col2\" >0.08</td>\n",
       "      <td id=\"T_a6350_row1_col3\" class=\"data row1 col3\" >0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a6350_level0_row2\" class=\"row_heading level0 row2\" >std</th>\n",
       "      <td id=\"T_a6350_row2_col0\" class=\"data row2 col0\" >0.85</td>\n",
       "      <td id=\"T_a6350_row2_col1\" class=\"data row2 col1\" >0.83</td>\n",
       "      <td id=\"T_a6350_row2_col2\" class=\"data row2 col2\" >0.88</td>\n",
       "      <td id=\"T_a6350_row2_col3\" class=\"data row2 col3\" >0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a6350_level0_row3\" class=\"row_heading level0 row3\" >min</th>\n",
       "      <td id=\"T_a6350_row3_col0\" class=\"data row3 col0\" >-1.45</td>\n",
       "      <td id=\"T_a6350_row3_col1\" class=\"data row3 col1\" >-1.98</td>\n",
       "      <td id=\"T_a6350_row3_col2\" class=\"data row3 col2\" >-1.35</td>\n",
       "      <td id=\"T_a6350_row3_col3\" class=\"data row3 col3\" >-1.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a6350_level0_row4\" class=\"row_heading level0 row4\" >25%</th>\n",
       "      <td id=\"T_a6350_row4_col0\" class=\"data row4 col0\" >-0.81</td>\n",
       "      <td id=\"T_a6350_row4_col1\" class=\"data row4 col1\" >-0.85</td>\n",
       "      <td id=\"T_a6350_row4_col2\" class=\"data row4 col2\" >-0.86</td>\n",
       "      <td id=\"T_a6350_row4_col3\" class=\"data row4 col3\" >-0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a6350_level0_row5\" class=\"row_heading level0 row5\" >50%</th>\n",
       "      <td id=\"T_a6350_row5_col0\" class=\"data row5 col0\" >0.19</td>\n",
       "      <td id=\"T_a6350_row5_col1\" class=\"data row5 col1\" >-0.18</td>\n",
       "      <td id=\"T_a6350_row5_col2\" class=\"data row5 col2\" >0.37</td>\n",
       "      <td id=\"T_a6350_row5_col3\" class=\"data row5 col3\" >0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a6350_level0_row6\" class=\"row_heading level0 row6\" >75%</th>\n",
       "      <td id=\"T_a6350_row6_col0\" class=\"data row6 col0\" >0.75</td>\n",
       "      <td id=\"T_a6350_row6_col1\" class=\"data row6 col1\" >0.05</td>\n",
       "      <td id=\"T_a6350_row6_col2\" class=\"data row6 col2\" >0.75</td>\n",
       "      <td id=\"T_a6350_row6_col3\" class=\"data row6 col3\" >0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a6350_level0_row7\" class=\"row_heading level0 row7\" >max</th>\n",
       "      <td id=\"T_a6350_row7_col0\" class=\"data row7 col0\" >1.60</td>\n",
       "      <td id=\"T_a6350_row7_col1\" class=\"data row7 col1\" >1.62</td>\n",
       "      <td id=\"T_a6350_row7_col2\" class=\"data row7 col2\" >1.15</td>\n",
       "      <td id=\"T_a6350_row7_col3\" class=\"data row7 col3\" >1.70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f62157faac0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(x_train.values)\n",
    "x_trainS = scaler.transform(x_train.values) #returns a numpy array\n",
    "x_testS = scaler.transform(x_test.values) #returns a numpy array\n",
    "x_trainD = pd.DataFrame(x_trainS, columns=x_train.columns, index=x_train.index)\n",
    "x_testD = pd.DataFrame(x_testS, columns=x_test.columns, index=x_test.index)\n",
    "display(x_trainD.describe().style.format(\"{0:.2f}\").set_caption(\"Training set après normalisation (avec scikit-learn):\"))\n",
    "display(x_testD.describe().style.format(\"{0:.2f}\").set_caption(\"Test set after après normalisation (avec scikit-learn):\"))\n",
    "x_train = x_trainS\n",
    "x_test = x_testS\n",
    "del x_trainD, x_testD, x_trainS, x_testS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7111b5f-5db1-457a-a4ed-a93902334ebe",
   "metadata": {},
   "source": [
    "#### d. Définition du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "776ea4a4-a5f4-4898-886d-cec103569b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(NE): #NE = nombre de neurones d'entrée\n",
    "    \n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Input(NE, name='iLayer'))\n",
    "    model.add(keras.layers.Dense(7, activation='relu', name='hLayer1'))\n",
    "    model.add(keras.layers.Dense(5, activation='relu', name='hLayer2'))\n",
    "    model.add(keras.layers.Dense(3, activation='softmax', name='oLayer'))\n",
    "    \n",
    "    model.compile(optimizer = 'adam',\n",
    "                  loss      = 'categorical_crossentropy',\n",
    "                  metrics   = ['accuracy'] )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32938fc-ef05-46d6-9f26-80a727d0bc8f",
   "metadata": {},
   "source": [
    "#### e. Apprentissage supervisé du réseau de neurones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "877b00e0-83b3-4540-ad09-ffa631fde346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train. Structure (shape) : (120, 4)\n",
      "x_test. Structure (shape) : (30, 4)\n",
      "y_train. Structure (shape) : (120, 3)\n",
      "y_test. Structure (shape) : (30, 3)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hLayer1 (Dense)              (None, 7)                 35        \n",
      "_________________________________________________________________\n",
      "hLayer2 (Dense)              (None, 5)                 40        \n",
      "_________________________________________________________________\n",
      "oLayer (Dense)               (None, 3)                 18        \n",
      "=================================================================\n",
      "Total params: 93\n",
      "Trainable params: 93\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-03 11:31:20.882638: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-06-03 11:31:20.882903: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-03 11:31:20.883621: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 4. Tune using inter_op_parallelism_threads for best performance.\n",
      "2022-06-03 11:31:20.992572: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-06-03 11:31:20.993039: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2099940000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s 33ms/step - loss: 1.1938 - accuracy: 0.0028 - val_loss: 1.1738 - val_accuracy: 0.0333\n",
      "Epoch 2/700\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.1451 - accuracy: 0.0499 - val_loss: 1.1394 - val_accuracy: 0.1333\n",
      "Epoch 3/700\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1.1191 - accuracy: 0.1338 - val_loss: 1.1160 - val_accuracy: 0.1333\n",
      "Epoch 4/700\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1.0974 - accuracy: 0.2752 - val_loss: 1.1036 - val_accuracy: 0.1333\n",
      "Epoch 5/700\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1.0893 - accuracy: 0.2393 - val_loss: 1.0950 - val_accuracy: 0.1333\n",
      "Epoch 6/700\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1.0794 - accuracy: 0.2378 - val_loss: 1.0872 - val_accuracy: 0.1667\n",
      "Epoch 7/700\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 1.0648 - accuracy: 0.3436 - val_loss: 1.0759 - val_accuracy: 0.2667\n",
      "Epoch 8/700\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 1.0464 - accuracy: 0.4204 - val_loss: 1.0527 - val_accuracy: 0.4000\n",
      "Epoch 9/700\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1.0096 - accuracy: 0.6827 - val_loss: 1.0215 - val_accuracy: 0.5000\n",
      "Epoch 10/700\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.9819 - accuracy: 0.6498 - val_loss: 0.9812 - val_accuracy: 0.7000\n",
      "Epoch 11/700\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.9301 - accuracy: 0.7737 - val_loss: 0.9361 - val_accuracy: 0.7000\n",
      "Epoch 12/700\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.8729 - accuracy: 0.7698 - val_loss: 0.8861 - val_accuracy: 0.6333\n",
      "Epoch 13/700\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.7707 - accuracy: 0.8289 - val_loss: 0.8409 - val_accuracy: 0.6333\n",
      "Epoch 14/700\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.7134 - accuracy: 0.7666 - val_loss: 0.7884 - val_accuracy: 0.6333\n",
      "Epoch 15/700\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.6934 - accuracy: 0.7465 - val_loss: 0.7406 - val_accuracy: 0.6333\n",
      "Epoch 16/700\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.6458 - accuracy: 0.7228 - val_loss: 0.6966 - val_accuracy: 0.6333\n",
      "Epoch 17/700\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.5359 - accuracy: 0.7676 - val_loss: 0.6632 - val_accuracy: 0.6000\n",
      "Epoch 18/700\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.5597 - accuracy: 0.6940 - val_loss: 0.6315 - val_accuracy: 0.6333\n",
      "Epoch 19/700\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.5285 - accuracy: 0.7308 - val_loss: 0.6060 - val_accuracy: 0.6333\n",
      "Epoch 20/700\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.4488 - accuracy: 0.7648 - val_loss: 0.5826 - val_accuracy: 0.6333\n",
      "Epoch 21/700\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.4318 - accuracy: 0.7469 - val_loss: 0.5656 - val_accuracy: 0.6333\n",
      "Epoch 22/700\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.5152 - accuracy: 0.6485 - val_loss: 0.5438 - val_accuracy: 0.6333\n",
      "Epoch 23/700\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.4263 - accuracy: 0.7515 - val_loss: 0.5368 - val_accuracy: 0.6333\n",
      "Epoch 24/700\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.3858 - accuracy: 0.7812 - val_loss: 0.5202 - val_accuracy: 0.6333\n",
      "Epoch 25/700\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3806 - accuracy: 0.8330 - val_loss: 0.5077 - val_accuracy: 0.6333\n",
      "Epoch 26/700\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.3695 - accuracy: 0.8128 - val_loss: 0.4931 - val_accuracy: 0.7000\n",
      "Epoch 27/700\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.3855 - accuracy: 0.8186 - val_loss: 0.4863 - val_accuracy: 0.7000\n",
      "Epoch 28/700\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.3618 - accuracy: 0.8261 - val_loss: 0.4766 - val_accuracy: 0.7000\n",
      "Epoch 29/700\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.3531 - accuracy: 0.8784 - val_loss: 0.4672 - val_accuracy: 0.7000\n",
      "Epoch 30/700\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.3782 - accuracy: 0.8664 - val_loss: 0.4583 - val_accuracy: 0.7000\n",
      "Epoch 31/700\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.3034 - accuracy: 0.9010 - val_loss: 0.4501 - val_accuracy: 0.7000\n",
      "Epoch 32/700\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3590 - accuracy: 0.8474 - val_loss: 0.4404 - val_accuracy: 0.7333\n",
      "Epoch 33/700\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3109 - accuracy: 0.8875 - val_loss: 0.4309 - val_accuracy: 0.7667\n",
      "Epoch 34/700\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3925 - accuracy: 0.8147 - val_loss: 0.4213 - val_accuracy: 0.7667\n",
      "Epoch 35/700\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.3409 - accuracy: 0.8680 - val_loss: 0.4122 - val_accuracy: 0.7667\n",
      "Epoch 36/700\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.2528 - accuracy: 0.9309 - val_loss: 0.4077 - val_accuracy: 0.7667\n",
      "Epoch 37/700\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.3410 - accuracy: 0.8498 - val_loss: 0.4004 - val_accuracy: 0.7667\n",
      "Epoch 38/700\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2928 - accuracy: 0.9202 - val_loss: 0.3916 - val_accuracy: 0.7667\n",
      "Epoch 39/700\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.2999 - accuracy: 0.8739 - val_loss: 0.3848 - val_accuracy: 0.7667\n",
      "Epoch 40/700\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.3186 - accuracy: 0.8683 - val_loss: 0.3718 - val_accuracy: 0.8000\n",
      "Epoch 41/700\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.3062 - accuracy: 0.8801 - val_loss: 0.3710 - val_accuracy: 0.7667\n",
      "Epoch 42/700\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.2346 - accuracy: 0.9573 - val_loss: 0.3605 - val_accuracy: 0.8000\n",
      "Epoch 43/700\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.2661 - accuracy: 0.9010 - val_loss: 0.3492 - val_accuracy: 0.8333\n",
      "Epoch 44/700\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2463 - accuracy: 0.9643 - val_loss: 0.3448 - val_accuracy: 0.8333\n",
      "Epoch 45/700\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.2470 - accuracy: 0.9525 - val_loss: 0.3362 - val_accuracy: 0.8333\n",
      "Epoch 46/700\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2088 - accuracy: 0.9669 - val_loss: 0.3291 - val_accuracy: 0.8333\n",
      "Epoch 47/700\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.2387 - accuracy: 0.9342 - val_loss: 0.3212 - val_accuracy: 0.8333\n",
      "Epoch 48/700\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.2126 - accuracy: 0.9763 - val_loss: 0.3156 - val_accuracy: 0.8333\n",
      "Epoch 49/700\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2162 - accuracy: 0.9708 - val_loss: 0.3107 - val_accuracy: 0.8333\n",
      "Epoch 50/700\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.2034 - accuracy: 0.9724 - val_loss: 0.2946 - val_accuracy: 0.9000\n",
      "Epoch 51/700\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1855 - accuracy: 0.9866 - val_loss: 0.2976 - val_accuracy: 0.9000\n",
      "Epoch 52/700\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.2624 - accuracy: 0.9631 - val_loss: 0.2869 - val_accuracy: 0.9000\n",
      "Epoch 53/700\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2136 - accuracy: 0.9597 - val_loss: 0.2824 - val_accuracy: 0.9000\n",
      "Epoch 54/700\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.2146 - accuracy: 0.9559 - val_loss: 0.2787 - val_accuracy: 0.9000\n",
      "Epoch 55/700\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1846 - accuracy: 0.9802 - val_loss: 0.2717 - val_accuracy: 0.9000\n",
      "Epoch 56/700\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1799 - accuracy: 0.9914 - val_loss: 0.2649 - val_accuracy: 0.9333\n",
      "Epoch 57/700\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.2041 - accuracy: 0.9647 - val_loss: 0.2556 - val_accuracy: 0.9333\n",
      "Epoch 58/700\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1888 - accuracy: 0.9847 - val_loss: 0.2527 - val_accuracy: 0.9333\n",
      "Epoch 59/700\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2099 - accuracy: 0.9491 - val_loss: 0.2494 - val_accuracy: 0.9333\n",
      "Epoch 60/700\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1644 - accuracy: 0.9841 - val_loss: 0.2465 - val_accuracy: 0.9333\n",
      "Epoch 61/700\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1724 - accuracy: 0.9558 - val_loss: 0.2360 - val_accuracy: 0.9667\n",
      "Epoch 62/700\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1654 - accuracy: 0.9828 - val_loss: 0.2326 - val_accuracy: 0.9667\n",
      "Epoch 63/700\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2091 - accuracy: 0.9554 - val_loss: 0.2281 - val_accuracy: 0.9667\n",
      "Epoch 64/700\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1564 - accuracy: 0.9850 - val_loss: 0.2234 - val_accuracy: 0.9667\n",
      "Epoch 65/700\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1388 - accuracy: 0.9737 - val_loss: 0.2185 - val_accuracy: 0.9667\n",
      "Epoch 66/700\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1783 - accuracy: 0.9705 - val_loss: 0.2141 - val_accuracy: 0.9667\n",
      "Epoch 67/700\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1315 - accuracy: 0.9751 - val_loss: 0.2092 - val_accuracy: 0.9667\n",
      "Epoch 68/700\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1527 - accuracy: 0.9534 - val_loss: 0.2113 - val_accuracy: 0.9667\n",
      "Epoch 69/700\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1250 - accuracy: 0.9733 - val_loss: 0.2043 - val_accuracy: 0.9667\n",
      "Epoch 70/700\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1360 - accuracy: 0.9539 - val_loss: 0.2058 - val_accuracy: 0.9333\n",
      "Epoch 71/700\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1445 - accuracy: 0.9796 - val_loss: 0.1957 - val_accuracy: 0.9667\n",
      "Epoch 72/700\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1537 - accuracy: 0.9542 - val_loss: 0.1978 - val_accuracy: 0.9333\n",
      "Epoch 73/700\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1245 - accuracy: 0.9789 - val_loss: 0.1919 - val_accuracy: 0.9667\n",
      "Epoch 74/700\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1576 - accuracy: 0.9421 - val_loss: 0.1870 - val_accuracy: 0.9667\n",
      "Epoch 75/700\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1201 - accuracy: 0.9758 - val_loss: 0.1877 - val_accuracy: 0.9667\n",
      "Epoch 76/700\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.0930 - accuracy: 0.9879 - val_loss: 0.1854 - val_accuracy: 0.9667\n",
      "Epoch 77/700\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1269 - accuracy: 0.9621 - val_loss: 0.1809 - val_accuracy: 0.9667\n",
      "Epoch 78/700\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1199 - accuracy: 0.9691 - val_loss: 0.1751 - val_accuracy: 0.9667\n",
      "Epoch 79/700\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1127 - accuracy: 0.9691 - val_loss: 0.1796 - val_accuracy: 0.9667\n",
      "Epoch 80/700\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1198 - accuracy: 0.9724 - val_loss: 0.1755 - val_accuracy: 0.9667\n",
      "Epoch 81/700\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1095 - accuracy: 0.9759 - val_loss: 0.1755 - val_accuracy: 0.9333\n",
      "Epoch 82/700\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0818 - accuracy: 0.9821 - val_loss: 0.1713 - val_accuracy: 0.9667\n",
      "Epoch 83/700\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1179 - accuracy: 0.9563 - val_loss: 0.1722 - val_accuracy: 0.9333\n",
      "Epoch 84/700\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0936 - accuracy: 0.9575 - val_loss: 0.1692 - val_accuracy: 0.9333\n",
      "Epoch 85/700\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1147 - accuracy: 0.9524 - val_loss: 0.1687 - val_accuracy: 0.9333\n",
      "Epoch 86/700\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1096 - accuracy: 0.9557 - val_loss: 0.1609 - val_accuracy: 0.9667\n",
      "Epoch 87/700\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0804 - accuracy: 0.9872 - val_loss: 0.1597 - val_accuracy: 0.9667\n",
      "Epoch 88/700\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0968 - accuracy: 0.9606 - val_loss: 0.1581 - val_accuracy: 0.9667\n",
      "Epoch 89/700\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1066 - accuracy: 0.9611 - val_loss: 0.1581 - val_accuracy: 0.9667\n",
      "Epoch 90/700\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0724 - accuracy: 0.9875 - val_loss: 0.1543 - val_accuracy: 0.9667\n",
      "Epoch 91/700\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1032 - accuracy: 0.9612 - val_loss: 0.1519 - val_accuracy: 0.9667\n",
      "Epoch 92/700\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0973 - accuracy: 0.9621 - val_loss: 0.1631 - val_accuracy: 0.9333\n",
      "Epoch 93/700\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.0933 - accuracy: 0.9704 - val_loss: 0.1503 - val_accuracy: 0.9667\n",
      "Epoch 94/700\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0792 - accuracy: 0.9762 - val_loss: 0.1525 - val_accuracy: 0.9333\n",
      "Epoch 95/700\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0770 - accuracy: 0.9776 - val_loss: 0.1546 - val_accuracy: 0.9333\n",
      "Epoch 96/700\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0701 - accuracy: 0.9779 - val_loss: 0.1514 - val_accuracy: 0.9333\n",
      "Epoch 97/700\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0977 - accuracy: 0.9555 - val_loss: 0.1503 - val_accuracy: 0.9333\n",
      "Epoch 98/700\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.0700 - accuracy: 0.9727 - val_loss: 0.1492 - val_accuracy: 0.9333\n",
      "Epoch 99/700\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1045 - accuracy: 0.9332 - val_loss: 0.1507 - val_accuracy: 0.9333\n",
      "Epoch 100/700\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.0981 - accuracy: 0.9585 - val_loss: 0.1414 - val_accuracy: 0.9667\n",
      "Epoch 101/700\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0694 - accuracy: 0.9781 - val_loss: 0.1483 - val_accuracy: 0.9333\n",
      "Epoch 102/700\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0756 - accuracy: 0.9781 - val_loss: 0.1451 - val_accuracy: 0.9333\n",
      "Epoch 103/700\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0924 - accuracy: 0.9551 - val_loss: 0.1413 - val_accuracy: 0.9333\n",
      "Epoch 104/700\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.0686 - accuracy: 0.9733 - val_loss: 0.1465 - val_accuracy: 0.9333\n",
      "Epoch 105/700\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.0653 - accuracy: 0.9719 - val_loss: 0.1462 - val_accuracy: 0.9333\n",
      "Epoch 106/700\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.0726 - accuracy: 0.9689 - val_loss: 0.1387 - val_accuracy: 0.9333\n",
      "Epoch 107/700\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.0838 - accuracy: 0.9637 - val_loss: 0.1422 - val_accuracy: 0.9333\n",
      "Epoch 108/700\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0796 - accuracy: 0.9456 - val_loss: 0.1431 - val_accuracy: 0.9333\n",
      "Epoch 109/700\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.0736 - accuracy: 0.9712 - val_loss: 0.1419 - val_accuracy: 0.9333\n",
      "Epoch 110/700\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1007 - accuracy: 0.9486 - val_loss: 0.1381 - val_accuracy: 0.9333\n",
      "Epoch 111/700\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0638 - accuracy: 0.9695 - val_loss: 0.1391 - val_accuracy: 0.9333\n",
      "Epoch 112/700\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.0813 - accuracy: 0.9536 - val_loss: 0.1402 - val_accuracy: 0.9333\n",
      "Epoch 113/700\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.0527 - accuracy: 0.9902 - val_loss: 0.1345 - val_accuracy: 0.9333\n",
      "Epoch 114/700\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.0763 - accuracy: 0.9526 - val_loss: 0.1443 - val_accuracy: 0.9333\n",
      "Epoch 115/700\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0733 - accuracy: 0.9688 - val_loss: 0.1340 - val_accuracy: 0.9333\n",
      "Epoch 116/700\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0735 - accuracy: 0.9687 - val_loss: 0.1276 - val_accuracy: 0.9667\n",
      "Epoch 117/700\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0488 - accuracy: 0.9832 - val_loss: 0.1429 - val_accuracy: 0.9333\n",
      "Epoch 118/700\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0771 - accuracy: 0.9532 - val_loss: 0.1352 - val_accuracy: 0.9333\n",
      "Epoch 119/700\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0626 - accuracy: 0.9689 - val_loss: 0.1362 - val_accuracy: 0.9333\n",
      "Epoch 120/700\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0661 - accuracy: 0.9951 - val_loss: 0.1414 - val_accuracy: 0.9333\n",
      "Epoch 121/700\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0520 - accuracy: 0.9869 - val_loss: 0.1315 - val_accuracy: 0.9333\n",
      "Epoch 122/700\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0742 - accuracy: 0.9714 - val_loss: 0.1355 - val_accuracy: 0.9333\n",
      "Epoch 123/700\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0650 - accuracy: 0.9601 - val_loss: 0.1258 - val_accuracy: 0.9667\n",
      "Epoch 124/700\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.0441 - accuracy: 0.9852 - val_loss: 0.1398 - val_accuracy: 0.9333\n",
      "Epoch 125/700\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1052 - accuracy: 0.9404 - val_loss: 0.1327 - val_accuracy: 0.9333\n",
      "Epoch 126/700\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0734 - accuracy: 0.9500 - val_loss: 0.1296 - val_accuracy: 0.9333\n",
      "Epoch 127/700\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0452 - accuracy: 0.9950 - val_loss: 0.1306 - val_accuracy: 0.9333\n",
      "Epoch 128/700\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0675 - accuracy: 0.9611 - val_loss: 0.1376 - val_accuracy: 0.9333\n",
      "Epoch 129/700\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0655 - accuracy: 0.9699 - val_loss: 0.1363 - val_accuracy: 0.9333\n",
      "Epoch 130/700\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0545 - accuracy: 0.9767 - val_loss: 0.1393 - val_accuracy: 0.9333\n",
      "Epoch 131/700\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0742 - accuracy: 0.9486 - val_loss: 0.1341 - val_accuracy: 0.9333\n",
      "Epoch 132/700\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0506 - accuracy: 0.9785 - val_loss: 0.1271 - val_accuracy: 0.9333\n",
      "Epoch 133/700\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.0639 - accuracy: 0.9641 - val_loss: 0.1255 - val_accuracy: 0.9333\n",
      "Epoch 134/700\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0461 - accuracy: 0.9754 - val_loss: 0.1346 - val_accuracy: 0.9333\n",
      "Epoch 135/700\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0557 - accuracy: 0.9718 - val_loss: 0.1306 - val_accuracy: 0.9333\n",
      "Epoch 136/700\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0529 - accuracy: 0.9676 - val_loss: 0.1324 - val_accuracy: 0.9333\n",
      "Epoch 137/700\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.0517 - accuracy: 0.9722 - val_loss: 0.1287 - val_accuracy: 0.9333\n",
      "Epoch 138/700\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.0865 - accuracy: 0.9234 - val_loss: 0.1319 - val_accuracy: 0.9333\n",
      "Epoch 139/700\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0537 - accuracy: 0.9658 - val_loss: 0.1299 - val_accuracy: 0.9333\n",
      "Epoch 140/700\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0575 - accuracy: 0.9641 - val_loss: 0.1287 - val_accuracy: 0.9333\n",
      "Epoch 141/700\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.0460 - accuracy: 0.9932 - val_loss: 0.1450 - val_accuracy: 0.9333\n",
      "Epoch 142/700\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0537 - accuracy: 0.9748 - val_loss: 0.1223 - val_accuracy: 0.9667\n",
      "Epoch 143/700\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.0674 - accuracy: 0.9671 - val_loss: 0.1399 - val_accuracy: 0.9333\n",
      "Epoch 144/700\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0444 - accuracy: 0.9938 - val_loss: 0.1261 - val_accuracy: 0.9333\n",
      "Epoch 145/700\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.0377 - accuracy: 0.9939 - val_loss: 0.1223 - val_accuracy: 0.9333\n",
      "Epoch 146/700\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0400 - accuracy: 0.9879 - val_loss: 0.1267 - val_accuracy: 0.9333\n",
      "Epoch 147/700\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.0537 - accuracy: 0.9759 - val_loss: 0.1266 - val_accuracy: 0.9333\n",
      "Epoch 148/700\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0359 - accuracy: 0.9842 - val_loss: 0.1331 - val_accuracy: 0.9333\n",
      "Epoch 149/700\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0661 - accuracy: 0.9735 - val_loss: 0.1254 - val_accuracy: 0.9333\n",
      "Epoch 150/700\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.0463 - accuracy: 0.9903 - val_loss: 0.1229 - val_accuracy: 0.9333\n",
      "Epoch 151/700\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0662 - accuracy: 0.9648 - val_loss: 0.1226 - val_accuracy: 0.9333\n",
      "Epoch 152/700\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.0604 - accuracy: 0.9892 - val_loss: 0.1238 - val_accuracy: 0.9333\n",
      "Epoch 00152: early stopping\n",
      "\n",
      "Duration :  00:00:18 415ms\n"
     ]
    }
   ],
   "source": [
    "vID.chrono_start()\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
    "print(f\"x_train. Structure (shape) : {x_train.shape}\")\n",
    "print(f\"x_test. Structure (shape) : {x_test.shape}\")\n",
    "print(f\"y_train. Structure (shape) : {y_train.shape}\")\n",
    "print(f\"y_test. Structure (shape) : {y_test.shape}\")\n",
    "ANNmodel=get_model( (4,)) # 4 neurones d'entrée\n",
    "ANNmodel.summary()\n",
    "vID.chrono_start()\n",
    "ANNhistory = ANNmodel.fit(x_train,\n",
    "                    y_train,\n",
    "                    epochs          = 700,\n",
    "                    batch_size      = 5,\n",
    "                    verbose         = 1,\n",
    "                    validation_data = (x_test, y_test),\n",
    "                    callbacks=[es])\n",
    "vID.chrono_show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f927a6-ce28-443a-b4f9-0c47140e51ef",
   "metadata": {},
   "source": [
    "#### f. Évaluation numérique globale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe7d2f5f-14a3-4484-9cc6-69a080e0212b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mx_train / loss      : 0.0506\u001b[0m\n",
      "\u001b[92mx_train/ accurracy  : 0.9833\u001b[0m\n",
      "\n",
      "\u001b[94mx_train / loss      : 0.1238\u001b[0m\n",
      "\u001b[94mx_train/ accurracy  : 0.9333\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "evalANN_on_Train = ANNmodel.evaluate(x_train, y_train, verbose=0)\n",
    "print(f\"{color.GREEN}x_train / loss      : {evalANN_on_Train[0]:5.4f}{color.OFF}\")\n",
    "print(f\"{color.GREEN}x_train/ accurracy  : {evalANN_on_Train[1]:5.4f}{color.OFF}\")\n",
    "print()\n",
    "evalANN_on_Test = ANNmodel.evaluate(x_test, y_test, verbose=0)\n",
    "print(f\"{color.BLUE}x_train / loss      : {evalANN_on_Test[0]:5.4f}{color.OFF}\")\n",
    "print(f\"{color.BLUE}x_train/ accurracy  : {evalANN_on_Test[1]:5.4f}{color.OFF}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5149669f-0ee6-4f8f-9f40-1cb91e4929ad",
   "metadata": {},
   "source": [
    "#### g. Comportement du modèle vis-à-vis de chaque espèce d'iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35c740a5-53e5-4776-8cea-b53af7589366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[92mCatégories uniques d'iris :\u001b[0m ['setosa' 'versicolor' 'virginica']\n",
      "\u001b[1m\u001b[94mTest Set\u001b[0m. Comparaison entre espèce prédite et espèce observée\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>setosa</th>\n",
       "      <th>versicolor</th>\n",
       "      <th>virginica</th>\n",
       "      <th>Espèce prédite</th>\n",
       "      <th>Espèce observée</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.02</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.98</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.02</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.02</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.49</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.94</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.04</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.02</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.02</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.04</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.02</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.88</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.12</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.09</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.98</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.58</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.04</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.99</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.92</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.04</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.88</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.99</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.99</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.99</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.03</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.93</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.04</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.63</td>\n",
       "      <td>virginica</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.93</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.99</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.47</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.47</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.05</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.04</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.02</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.98</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.02</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.02</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.82</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.98</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.87</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.99</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.02</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.09</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.02</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.09</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.08</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.02</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.04</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.91</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.94</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.96</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     setosa  versicolor  virginica Espèce prédite Espèce observée\n",
       "113    0.00        0.00       1.00      virginica       virginica\n",
       "79     0.00        0.98       0.02     versicolor      versicolor\n",
       "31     1.00        0.00       0.00         setosa          setosa\n",
       "117    0.00        0.02       0.98      virginica       virginica\n",
       "55     0.00        0.98       0.02     versicolor      versicolor\n",
       "96     0.00        0.98       0.02     versicolor      versicolor\n",
       "141    0.00        0.00       1.00      virginica       virginica\n",
       "72     0.00        0.51       0.49     versicolor      versicolor\n",
       "3      1.00        0.00       0.00         setosa          setosa\n",
       "110    0.00        0.06       0.94      virginica       virginica\n",
       "53     0.00        0.96       0.04     versicolor      versicolor\n",
       "23     1.00        0.00       0.00         setosa          setosa\n",
       "19     1.00        0.00       0.00         setosa          setosa\n",
       "15     1.00        0.00       0.00         setosa          setosa\n",
       "25     1.00        0.00       0.00         setosa          setosa\n",
       "90     0.00        0.99       0.01     versicolor      versicolor\n",
       "93     0.00        0.99       0.01     versicolor      versicolor\n",
       "82     0.00        0.98       0.02     versicolor      versicolor\n",
       "89     0.00        0.98       0.02     versicolor      versicolor\n",
       "69     0.00        0.99       0.01     versicolor      versicolor\n",
       "51     0.00        0.96       0.04     versicolor      versicolor\n",
       "18     1.00        0.00       0.00         setosa          setosa\n",
       "99     0.00        0.98       0.02     versicolor      versicolor\n",
       "118    0.00        0.00       1.00      virginica       virginica\n",
       "131    0.00        0.12       0.88      virginica       virginica\n",
       "41     0.99        0.01       0.00         setosa          setosa\n",
       "6      1.00        0.00       0.00         setosa          setosa\n",
       "46     1.00        0.00       0.00         setosa          setosa\n",
       "26     1.00        0.00       0.00         setosa          setosa\n",
       "5      1.00        0.00       0.00         setosa          setosa\n",
       "4      1.00        0.00       0.00         setosa          setosa\n",
       "66     0.00        0.88       0.12     versicolor      versicolor\n",
       "10     1.00        0.00       0.00         setosa          setosa\n",
       "76     0.00        0.91       0.09     versicolor      versicolor\n",
       "143    0.00        0.00       1.00      virginica       virginica\n",
       "124    0.00        0.02       0.98      virginica       virginica\n",
       "28     1.00        0.00       0.00         setosa          setosa\n",
       "134    0.00        0.42       0.58      virginica       virginica\n",
       "7      1.00        0.00       0.00         setosa          setosa\n",
       "140    0.00        0.00       1.00      virginica       virginica\n",
       "64     0.00        0.96       0.04     versicolor      versicolor\n",
       "12     1.00        0.00       0.00         setosa          setosa\n",
       "128    0.00        0.00       1.00      virginica       virginica\n",
       "111    0.00        0.01       0.99      virginica       virginica\n",
       "114    0.00        0.00       1.00      virginica       virginica\n",
       "35     1.00        0.00       0.00         setosa          setosa\n",
       "8      1.00        0.00       0.00         setosa          setosa\n",
       "101    0.00        0.00       1.00      virginica       virginica\n",
       "137    0.00        0.08       0.92      virginica       virginica\n",
       "95     0.00        0.96       0.04     versicolor      versicolor\n",
       "112    0.00        0.00       1.00      virginica       virginica\n",
       "149    0.00        0.12       0.88      virginica       virginica\n",
       "80     0.00        0.99       0.01     versicolor      versicolor\n",
       "130    0.00        0.01       0.99      virginica       virginica\n",
       "22     1.00        0.00       0.00         setosa          setosa\n",
       "105    0.00        0.00       1.00      virginica       virginica\n",
       "0      1.00        0.00       0.00         setosa          setosa\n",
       "147    0.00        0.01       0.99      virginica       virginica\n",
       "136    0.00        0.01       0.99      virginica       virginica\n",
       "40     1.00        0.00       0.00         setosa          setosa\n",
       "88     0.00        0.96       0.03     versicolor      versicolor\n",
       "126    0.00        0.07       0.93      virginica       virginica\n",
       "27     1.00        0.00       0.00         setosa          setosa\n",
       "59     0.00        0.96       0.04     versicolor      versicolor\n",
       "43     1.00        0.00       0.00         setosa          setosa\n",
       "77     0.00        0.37       0.63      virginica      versicolor\n",
       "100    0.00        0.00       1.00      virginica       virginica\n",
       "42     1.00        0.00       0.00         setosa          setosa\n",
       "106    0.00        0.07       0.93      virginica       virginica\n",
       "30     1.00        0.00       0.00         setosa          setosa\n",
       "107    0.00        0.01       0.99      virginica       virginica\n",
       "11     1.00        0.00       0.00         setosa          setosa\n",
       "13     1.00        0.00       0.00         setosa          setosa\n",
       "14     1.00        0.00       0.00         setosa          setosa\n",
       "70     0.00        0.53       0.47     versicolor      versicolor\n",
       "17     1.00        0.00       0.00         setosa          setosa\n",
       "2      1.00        0.00       0.00         setosa          setosa\n",
       "133    0.00        0.53       0.47     versicolor       virginica\n",
       "33     1.00        0.00       0.00         setosa          setosa\n",
       "91     0.00        0.95       0.05     versicolor      versicolor\n",
       "135    0.00        0.00       1.00      virginica       virginica\n",
       "87     0.00        0.96       0.04     versicolor      versicolor\n",
       "37     1.00        0.00       0.00         setosa          setosa\n",
       "49     1.00        0.00       0.00         setosa          setosa\n",
       "32     1.00        0.00       0.00         setosa          setosa\n",
       "65     0.00        0.98       0.02     versicolor      versicolor\n",
       "81     0.00        0.99       0.01     versicolor      versicolor\n",
       "148    0.00        0.02       0.98      virginica       virginica\n",
       "9      1.00        0.00       0.00         setosa          setosa\n",
       "73     0.00        0.99       0.01     versicolor      versicolor\n",
       "58     0.00        0.98       0.02     versicolor      versicolor\n",
       "67     0.00        0.98       0.02     versicolor      versicolor\n",
       "119    0.00        0.18       0.82      virginica       virginica\n",
       "16     1.00        0.00       0.00         setosa          setosa\n",
       "103    0.00        0.02       0.98      virginica       virginica\n",
       "60     0.00        0.99       0.01     versicolor      versicolor\n",
       "127    0.00        0.13       0.87      virginica       virginica\n",
       "21     1.00        0.00       0.00         setosa          setosa\n",
       "121    0.00        0.01       0.99      virginica       virginica\n",
       "102    0.00        0.00       1.00      virginica       virginica\n",
       "50     0.00        0.98       0.02     versicolor      versicolor\n",
       "62     0.00        0.99       0.01     versicolor      versicolor\n",
       "132    0.00        0.00       1.00      virginica       virginica\n",
       "84     0.00        0.91       0.09     versicolor      versicolor\n",
       "24     1.00        0.00       0.00         setosa          setosa\n",
       "75     0.00        0.98       0.02     versicolor      versicolor\n",
       "56     0.00        0.91       0.09     versicolor      versicolor\n",
       "45     1.00        0.00       0.00         setosa          setosa\n",
       "52     0.00        0.92       0.08     versicolor      versicolor\n",
       "115    0.00        0.00       1.00      virginica       virginica\n",
       "71     0.00        0.98       0.02     versicolor      versicolor\n",
       "85     0.00        0.96       0.04     versicolor      versicolor\n",
       "120    0.00        0.00       1.00      virginica       virginica\n",
       "38     1.00        0.00       0.00         setosa          setosa\n",
       "122    0.00        0.00       1.00      virginica       virginica\n",
       "20     1.00        0.00       0.00         setosa          setosa\n",
       "109    0.00        0.00       1.00      virginica       virginica\n",
       "125    0.00        0.09       0.91      virginica       virginica\n",
       "116    0.00        0.06       0.94      virginica       virginica\n",
       "123    0.00        0.04       0.96      virginica       virginica"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'erreurs : 2\n",
      "\n",
      "\u001b[1m\u001b[91mTest Set\u001b[0m. Comparaison entre espèce prédite et espèce observée.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>setosa</th>\n",
       "      <th>versicolor</th>\n",
       "      <th>virginica</th>\n",
       "      <th>Espèce prédite</th>\n",
       "      <th>Espèce observée</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.20</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.02</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.07</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.08</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.52</td>\n",
       "      <td>virginica</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.02</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.16</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.80</td>\n",
       "      <td>virginica</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.06</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.02</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.02</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.03</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.66</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.83</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.99</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.99</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     setosa  versicolor  virginica Espèce prédite Espèce observée\n",
       "1      1.00        0.00       0.00         setosa          setosa\n",
       "29     1.00        0.00       0.00         setosa          setosa\n",
       "34     1.00        0.00       0.00         setosa          setosa\n",
       "36     1.00        0.00       0.00         setosa          setosa\n",
       "39     1.00        0.00       0.00         setosa          setosa\n",
       "44     1.00        0.00       0.00         setosa          setosa\n",
       "47     1.00        0.00       0.00         setosa          setosa\n",
       "48     1.00        0.00       0.00         setosa          setosa\n",
       "54     0.00        0.80       0.20     versicolor      versicolor\n",
       "57     0.00        0.98       0.02     versicolor      versicolor\n",
       "61     0.00        0.93       0.07     versicolor      versicolor\n",
       "63     0.00        0.91       0.08     versicolor      versicolor\n",
       "68     0.00        0.48       0.52      virginica      versicolor\n",
       "74     0.00        0.98       0.02     versicolor      versicolor\n",
       "78     0.00        0.84       0.16     versicolor      versicolor\n",
       "83     0.00        0.20       0.80      virginica      versicolor\n",
       "86     0.00        0.94       0.06     versicolor      versicolor\n",
       "92     0.00        0.99       0.01     versicolor      versicolor\n",
       "94     0.00        0.98       0.02     versicolor      versicolor\n",
       "97     0.00        0.98       0.02     versicolor      versicolor\n",
       "98     0.00        0.97       0.03     versicolor      versicolor\n",
       "104    0.00        0.00       1.00      virginica       virginica\n",
       "108    0.00        0.00       1.00      virginica       virginica\n",
       "129    0.00        0.34       0.66      virginica       virginica\n",
       "138    0.00        0.17       0.83      virginica       virginica\n",
       "139    0.00        0.01       0.99      virginica       virginica\n",
       "142    0.00        0.00       1.00      virginica       virginica\n",
       "144    0.00        0.00       1.00      virginica       virginica\n",
       "145    0.00        0.00       1.00      virginica       virginica\n",
       "146    0.00        0.01       0.99      virginica       virginica"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'erreurs : 2\n"
     ]
    }
   ],
   "source": [
    "usp = dfi['species'].unique()\n",
    "print(f\"{color.BOLD}{color.GREEN}Catégories uniques d'iris :{color.OFF} {usp}\")\n",
    "# cette correspondance élément 0 <-> setosa ; élément 1 <-> versicolor ; élément 2 <-> virginica\n",
    "# va servir à transformer les probabilités les plus élevées en espèce d'iris\n",
    "\n",
    "y_train_hat=ANNmodel.predict(x_train)\n",
    "ytr_hD = pd.DataFrame(y_train_hat, columns=usp, index=y_train.index)\n",
    "# argmax renvoie l'indice de la valeur maximale selon un axe (0 = ligne / 1 = colonne)\n",
    "# ça va ici nous renvoyer pour chaque ligne le numéro de la colonne qui contient la plus grande valeur de probabilité\n",
    "# on convertit maintenant 0, 1 & 2 en espèce d'iris\n",
    "iris_tr_hat = usp[np.argmax(y_train_hat,axis=1)]\n",
    "# on ajoute cette colonne au dataframe ytr_hD\n",
    "ytr_hD['Espèce prédite'] = pd.DataFrame(iris_tr_hat, index=y_train.index)\n",
    "ytr_hD['Espèce observée'] = pd.DataFrame(y_train_species, index=y_train.index)\n",
    "print(f\"{color.BOLD}{color.BLUE}Test Set{color.OFF}. Comparaison entre espèce prédite et espèce observée\")\n",
    "pd.set_option('display.max_rows', None) #on veut afficher toutes les lignes des DataFrames\n",
    "pd.options.display.float_format = '{:,.2f}'.format #on formatte les probabilités, sinon c'est illisible\n",
    "display(ytr_hD)\n",
    "pd.set_option('display.max_rows', 10) #reset de l'affichage: 5 premières et 5 dernières lignes\n",
    "pd.options.display.float_format = None #reset de l'affichage: format standard \n",
    "diff_Pred_Obs=np.where(ytr_hD['Espèce prédite'] == ytr_hD['Espèce observée'], 0, 1)\n",
    "print(f\"Nombre d'erreurs : {np.sum(diff_Pred_Obs)}\")\n",
    "\n",
    "print()\n",
    "y_test_hat=ANNmodel.predict(x_test)\n",
    "ytt_hD = pd.DataFrame(y_test_hat, columns=usp, index=y_test.index)\n",
    "# argmax renvoie l'indice de la valeur maximale selon un axe (0 = ligne / 1 = colonne)\n",
    "# ça va ici nous renvoyer pour chaque ligne le numéro de la colonne qui contient la plus grande valeur de probabilité\n",
    "# on convertit maintenant 0, 1 & 2 en espèce d'iris\n",
    "iris_tt_hat = usp[np.argmax(y_test_hat,axis=1)]\n",
    "# on ajoute cette colonne au dataframe ytt_hD\n",
    "ytt_hD['Espèce prédite'] = pd.DataFrame(iris_tt_hat, index=y_test.index)\n",
    "ytt_hD['Espèce observée'] = pd.DataFrame(y_test_species, index=y_test.index)\n",
    "print(f\"{color.BOLD}{color.RED}Test Set{color.OFF}. Comparaison entre espèce prédite et espèce observée.\")\n",
    "pd.set_option('display.max_rows', None) #on veut afficher toutes les lignes des DataFrames\n",
    "pd.options.display.float_format = '{:,.2f}'.format #on formatte les probabilités, sinon c'est illisible\n",
    "display(ytt_hD)\n",
    "pd.set_option('display.max_rows', 10) #reset de l'affichage: 5 premières et 5 dernières lignes\n",
    "pd.options.display.float_format = None #reset de l'affichage: \n",
    "diff_Pred_Obs=np.where(ytt_hD['Espèce prédite'] == ytt_hD['Espèce observée'], 0, 1)\n",
    "print(f\"Nombre d'erreurs : {np.sum(diff_Pred_Obs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55fe30e-ce3d-49bf-b488-6fe9bff3291b",
   "metadata": {},
   "source": [
    "#### h. Bilan de la performance du modèle prédictif sous forme de matrice de confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "866bd474-9393-4311-b165-0f66d021e221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set. Matrice de confusion\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set. Matrice de confusion\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm_labels = dfi['species'].unique()\n",
    "print(\"Training set. Matrice de confusion\")\n",
    "cm_tr = confusion_matrix(np.argmax(y_train.to_numpy(),axis=1), np.argmax(y_train_hat,axis=1))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_tr, display_labels=cm_labels)\n",
    "disp.plot(cmap=plt.cm.Blues) #ici cm = diminutif de colormap dans matplotlib\n",
    "plt.show()\n",
    "print(\"Test set. Matrice de confusion\")\n",
    "cm_tt = confusion_matrix(np.argmax(y_test.to_numpy(),axis=1), np.argmax(y_test_hat,axis=1))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_tt, display_labels=cm_labels)\n",
    "disp.plot(cmap=plt.cm.Blues) #ici cm = diminutif de colormap dans matplotlib\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af354bcb",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Fin à:** Monday 30 May 2022, 22:37:29  \n",
       "**Durée:** 00:03:28 649ms"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<p style=\"text-align: center\"><img width=\"800px\" src=\"./svg/logoEnd.svg\" style=\"margin-left:auto; margin-right:auto\"></img></p>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vID.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fad06d-6413-4793-b945-a7d707839fee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
