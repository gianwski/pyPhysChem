{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8de690ce-49d6-4387-b242-fe36280ca9dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "h1, h2, h3, h4, h5, h6 {\n",
       "  font-family: Verdana, \"DejaVu Sans\", \"Bitstream Vera Sans\", Geneva, sans-serif;\n",
       "  font-weight: bold;\n",
       "}\n",
       "body {\n",
       "  font-family: Verdana, \"DejaVu Sans\", \"Bitstream Vera Sans\", Geneva, sans-serif;\n",
       "  font-weight: 200;\n",
       "}\n",
       "h1 {\n",
       "  border: 0px solid #333;\n",
       "  padding: 30px ;\n",
       "  color: white;\n",
       "  background: #b11d01;\n",
       "  text-align: center;\n",
       "}\n",
       "h2 {\n",
       "  border: 3px solid #333;\n",
       "  padding: 18px ;\n",
       "  color: #b11d01;\n",
       "  background: #ffffff;\n",
       "  text-align: center;\n",
       "}\n",
       "h3 {\n",
       "  border: 0px solid #333;\n",
       "  padding: 12px ;\n",
       "  color: #000000;\n",
       "  background: #c1c1c1;\n",
       "  text-align: left;\n",
       "}\n",
       "h4 {\n",
       "  border: 0px solid #333;\n",
       "  padding: 2px ;\n",
       "  color: #000000;\n",
       "  background: #d9fffc;\n",
       "  text-align: left;\n",
       "}\n",
       "div.warn {    \n",
       "    background-color: #fcf2f2;\n",
       "    border-color: #dFb5b4;\n",
       "    border-left: 5px solid #dfb5b4;\n",
       "    padding: 0.5em;\n",
       "    font-weight: 200;\n",
       "    }\n",
       "div.rq {    \n",
       "    background-color: #e2e2e2;\n",
       "    border-color: #969696;\n",
       "    border-left: 5px solid #969696;\n",
       "    padding: 0.5em;\n",
       "    font-weight: 200;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Début à:** Tuesday 31 May 2022, 17:56:46  \n",
       "**Hostname:** insa-11357 (Linux)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<p style=\"text-align: center\"><img width=\"800px\" src=\"./svg/logoBegin.svg\" style=\"margin-left:auto; margin-right:auto\"></img></p>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Démarrage du thème 3\n",
    "import visualID as vID\n",
    "from visualID import color\n",
    "vID.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b71cea",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Traitement statistique de données\n",
    "## 3. Apprentissage supervisé (*supervised Machine Learning*) appliqué à la classification<br>(régression logistique)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d43eab3-6d78-4c15-96c5-797e75ee940a",
   "metadata": {},
   "source": [
    "<div class=\"warn\">\n",
    "    <b style='color:red'>Ce thème n'est pas si complexe, mais l'analyse du code est réservée aux plus curieux et motivés.</b>\n",
    "    <br>Il a pour objectif de montrer qu'il est possible de prédire une valeur sur la base d'une corrélation multifactorielle entre une <b>classe d'objets</b> (ici des espèces d'iris) et des <b>propriétés</b> (ou descripteurs, ici les largeurs et longueurs des pétales et des sépales) \n",
    "    <br><b style='color:red'>Les moins curieux doivent <i>a minima</i> lire les commentaires et exécuter ce code pour en comprendre le principe.</b>\n",
    "   </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2f60c2-8759-4019-8dea-b692e73eaee6",
   "metadata": {},
   "source": [
    "### 3.1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1a5449-7e81-4541-a826-da0b12074809",
   "metadata": {},
   "source": [
    "#### 3.1.a. Objectif et principe général\n",
    "On a vu dans la partie précédente (statistiques et régression) qu'il est possible de prédire une valeur ($\\hat{y}$) sur la base d'une régression, c'est-à-dire du *fit* d'une équation mathématique qui relie deux variables entre elles ($y$ et $x$). On a pour cela utilisé les outils de régression offerts par la librairie `SciPy`. On a pu ainsi prédire la longueur d'un pétale d'iris, connaissant sa largeur, compte tenu de la relation linéaire entre longueur et largeur.\n",
    "\n",
    "On a également constaté dans la première partie que la distribution jointe des caractéristiques longueurs et largeurs des pétales (`jointplot`) est presque suffisante pour classifier les 3 espèce d'iris (figure de gauche). La zone de recouvrement entre caractéristiques de pétales des espèces <i>versicolor</i> et <i>virginica</i> ne permet malheureusement pas de trancher entre grands iris <i>versicolor</i> et petits iris <i>virginica</i>. On voit sur la figure de droite que les sépales des iris <i>setosa</i> ont des dimensions différentes des deux autres, alors que <i>versicolor</i> et <i>virginica</i> ont pour la plupart des sépales de dimensions similaires.\n",
    "<p style=\"text-align: center\"><img width=\"900px\" src=\"./svg/jointplot_petals-sepals_classification.png\" style=\"margin-left:auto; margin-right:auto\" id=\"img_jpc\"></img></p>\n",
    "\n",
    "<div class=\"warn\">\n",
    "Le premier objectif de ce TP est d'entraîner un modèle d'Intelligence Artificielle (IA) à <span style=\"color:red\"><b>classifier</b></span> les espèces d'iris sur la base des <span style=\"color:red\">longueurs (L<sub>P</sub>) et largeurs (&ell;<sub>P</sub>) de leurs pétales</span>. L'architecture est la suivante :\n",
    "\n",
    "<img width=\"350px\" src=\"./svg/IA-petales.png\" style=\"margin-left:auto; margin-right:auto; display: block;\" id=\"img_IA_jpc\"></img>   \n",
    "    \n",
    "C'est-à-dire qu'on va spécifier 2 paramètres en entrée, et qu'on veut obtenir en sortie les probabilités <i>P</i> que l'espèce d'iris caractérisée par ces deux propriétés soit de la famille <i>setosa</i>, <i>versicolor</i> ou <i>virginica</i>.\n",
    "</div>\n",
    "\n",
    "Il faut d'abord entraîner un modèle à faire un lien entre les 2 caractéristiques de pétales d'une part et espèce d'iris d'autre part. On parle d'**apprentissage supervisé** (*supervised machine learning*). Il existe plusieurs modèles statistiques qui peuvent faire ce type d'apprentissage visant à classifier des individus : arbres de décision, séparateurs à vaste marge (*support-vector machine*, SVM), réseaux de neurones artificiels (*artificial neural network*, ANN)... Même si ce n'est pas le plus efficace pour un problème aussi simple que celui-ci, on va utiliser une méthode d'apprentissage profond (*deep learning*), qui est un réseau de neurones particulier. On va découvrir que mettre au point un modèle de ce type n'est en réalité pas si compliqué que ça.\n",
    "\n",
    "Voici à quoi ressemble dans ce cas précis une boîte noire exploitant le deep learning : \n",
    "\n",
    "<img width=\"250px\" src=\"./svg/ANN-petales.png\" style=\"margin-left:auto; margin-right:auto; display: block;\" id=\"img_ANN_jpc\"></img>  \n",
    "\n",
    "Elle est constituée de neurones artificiels tous connectés entre eux : (a) deux neurones d'entrée qui vont recevoir pour chaque espèce les largeurs et longueurs des pétales; (b) trois neurones de sortie qui vont contenir la probabilité pour que l'iris de cette taille soit *setosa* (*P*<sub>1</sub>), *versicolor* (*P*<sub>1</sub>) ou *virginica* (*P*<sub>3</sub>); (c) deux couches intermédiaires de neurones. Ces couches intermédiaires sont appelées couches cachées. On parle de *deep learning* pour tout ANN qui contient un mlinimum de deux couches cachées."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02aa070-ddf4-4bb4-bb26-5043ee7ca53f",
   "metadata": {},
   "source": [
    "#### 3.1.b. Importation des librairies utiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6568ba3-8b12-4725-a890-132a9de260b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib as mp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a625d707-1cc5-45eb-bdc0-8be3cfe2e9b2",
   "metadata": {},
   "source": [
    "### 3.2. Préparation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7334ed83-f6aa-4f7e-b6a1-7e49b8b9da66",
   "metadata": {},
   "source": [
    "#### 3.2.a. Lecture de la base de données qui ont été adaptées au problème\n",
    "Les données brutes sont en général mal adaptées aux algorithmes d'apprentissage automatique. La/le *data scientist* doit faire en amont un travail de transformation de ces données. On a ici appliqué au préalable un \"encodage 1 parmi n\" (ou *one-hot-encoding*) des espèces d'iris (les plus curieu(x)(ses) peuvent se référer à l'annexe). On va lire la nouvelle base de données (nommée iris_ohe.csv) afin de plus facilement comprendre en quoi consiste cet encodage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef2fe4da-b86e-4c95-8f97-84f8c0f56215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dfi. Structure (shape) :(150, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "      <th>setosa</th>\n",
       "      <th>versicolor</th>\n",
       "      <th>virginica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>virginica</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width    species  setosa  \\\n",
       "0             5.1          3.5           1.4          0.2     setosa     1.0   \n",
       "1             4.9          3.0           1.4          0.2     setosa     1.0   \n",
       "2             4.7          3.2           1.3          0.2     setosa     1.0   \n",
       "3             4.6          3.1           1.5          0.2     setosa     1.0   \n",
       "4             5.0          3.6           1.4          0.2     setosa     1.0   \n",
       "..            ...          ...           ...          ...        ...     ...   \n",
       "145           6.7          3.0           5.2          2.3  virginica     0.0   \n",
       "146           6.3          2.5           5.0          1.9  virginica     0.0   \n",
       "147           6.5          3.0           5.2          2.0  virginica     0.0   \n",
       "148           6.2          3.4           5.4          2.3  virginica     0.0   \n",
       "149           5.9          3.0           5.1          1.8  virginica     0.0   \n",
       "\n",
       "     versicolor  virginica  \n",
       "0           0.0        0.0  \n",
       "1           0.0        0.0  \n",
       "2           0.0        0.0  \n",
       "3           0.0        0.0  \n",
       "4           0.0        0.0  \n",
       "..          ...        ...  \n",
       "145         0.0        1.0  \n",
       "146         0.0        1.0  \n",
       "147         0.0        1.0  \n",
       "148         0.0        1.0  \n",
       "149         0.0        1.0  \n",
       "\n",
       "[150 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfi=pd.read_csv('./iris-data/iris_ohe.csv', sep=\"\\t\") #les colonnes sont séparées par des tabulations\n",
    "print(f\"Dfi. Structure (shape) :{dfi.shape}\")\n",
    "display(dfi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcaf0845-966f-444f-b0a3-2f9da914906f",
   "metadata": {},
   "source": [
    "Le nouveau ficher de données contient 3 nouvelles colonnes (*setosa*, *versicolor*, *virginica*), qui ne contient que des 0 ou des 1, qui ne sont rien d'autre que les probabilités que chacune des fleurs d'iris soit setosa, versicolor ou virginica. Comme c'est un botaniste qui a établi de façon sûre la classification de cette base de données, les probabilités ne peuvent valoir que 0 ou 1 (et bien entendu il ne peut y avoir qu'une seule valeur '1.0' par ligne). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139cdc56-49f8-4775-abb6-1e9b2ff1b292",
   "metadata": {},
   "source": [
    "#### 3.2.b. Séparation des données en deux sous-ensembles d'apprentissage et de test\n",
    "On est au c&oelig;ur de l'apprentissage automatique :\n",
    "    <li> les algorithmes doivent être entraînés\n",
    "    <li> pour entraîner un algorithme, on va lui donner une multitude d'exemples et, en fonction de la différence entre le résultat obtenu et le résultat attendu, le système va mettre à jour ses \"coefficients\" : c'est la phase d'apprentissage. Cette optimisation des coefficients se fait en minimisant l'écart entre propriété prédite et propriété réelle (la propriété dans ce cas étant l'espèce d'iris)\n",
    "    <li> dans le cas d'un réseau de neurones, les coefficients sont les poids des connexions neuronales, ainsi qu'un paramètre caractéristique de chaque neurone\n",
    "    <li> comme pour tout apprentissage, il faut vérifier que les acquis sont solides, c'est la phase de test. Une fois l'algorithme entraîné, on va lui soumettre de nouveaux exemples connus et évaluer sa capacité à donner la bonne réponse.\n",
    "    \n",
    "Tout jeu de données est séparé en deux sous-ensembles :\n",
    "    <li> un jeu de données d'<b>apprentissage</b>\n",
    "    <li> un jeu de données de <b>test</b>, indépendantes du jeu de données d'apprentissage, mais qui suit la même distribution de probabilité\n",
    "\n",
    "(C'est ici une approche simplifiée. Dans une approche plus rigoureuse, on sépare la base de données en trois jeux : apprentissage, validation, test).\n",
    "        \n",
    "<div class=\"rq\">        \n",
    "Le principe est résumé dans la figure ci-dessous :\n",
    "        \n",
    "<img width=\"550px\" src=\"./svg/holdout.png\" style=\"margin-left:auto; margin-right:auto; display: block;\" id=\"img_IA_holdout\"></img>  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0470f71-6f34-4ccf-9e56-836928e32004",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train :  (120, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>3.8</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>4.6</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>6.3</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>4.9</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>4.9</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>3.9</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     petal_length  petal_width\n",
       "80            3.8          1.1\n",
       "91            4.6          1.4\n",
       "107           6.3          1.8\n",
       "29            1.6          0.2\n",
       "84            4.5          1.5\n",
       "..            ...          ...\n",
       "72            4.9          1.5\n",
       "123           4.9          1.8\n",
       "77            5.0          1.7\n",
       "59            3.9          1.4\n",
       "149           5.1          1.8\n",
       "\n",
       "[120 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train :  (120, 3) y_train_species :  (120, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>setosa</th>\n",
       "      <th>versicolor</th>\n",
       "      <th>virginica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     setosa  versicolor  virginica\n",
       "80      0.0         1.0        0.0\n",
       "91      0.0         1.0        0.0\n",
       "107     0.0         0.0        1.0\n",
       "29      1.0         0.0        0.0\n",
       "84      0.0         1.0        0.0\n",
       "..      ...         ...        ...\n",
       "72      0.0         1.0        0.0\n",
       "123     0.0         0.0        1.0\n",
       "77      0.0         1.0        0.0\n",
       "59      0.0         1.0        0.0\n",
       "149     0.0         0.0        1.0\n",
       "\n",
       "[120 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        species\n",
       "80   versicolor\n",
       "91   versicolor\n",
       "107   virginica\n",
       "29       setosa\n",
       "84   versicolor\n",
       "..          ...\n",
       "72   versicolor\n",
       "123   virginica\n",
       "77   versicolor\n",
       "59   versicolor\n",
       "149   virginica\n",
       "\n",
       "[120 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# création d'un jeu de données sous forme de dataFrame (data_train) qui contient 80% des échantillons, sélectionnés de façon aléatoire\n",
    "# ce sont les données qui vont servir à l'entraînement de l'algorithme\n",
    "data_train = dfi.sample(frac=0.8, axis='index') \n",
    "# création d'un nouveau dataFrame (data_test) qui contient les 20% restants\n",
    "# ce sont les données qui vont servir à tester l'algorithme sur des données qui lui sont inconnues\n",
    "data_test  = dfi.drop(data_train.index)\n",
    "\n",
    "# sélection des données d'apprentissage (d'entraînement)\n",
    "# x_train contient l'input, c'est-à-dire la largeur et la longueur de chacun des pétales du jeu de données data_train \n",
    "x_train = data_train[['petal_length','petal_width']]\n",
    "# y_train contient ce qu'on veut faire apprendre à l'algorithme, c'est-à-dire le type de chacun  des iris du jeu de données data_train. \n",
    "# comme on veut que l'algorithme prédise des probabilités, on va lui faire apprendre ce type d'information\n",
    "y_train = data_train[['setosa','versicolor','virginica']]\n",
    "y_train_species = data_train[['species']] #sera utile à la fin pour comparer la prédiction et l'espèce réelle\n",
    "\n",
    "# sélection des données de test\n",
    "# on fait pareil que précédemment, mais pour tester l'algorithme (l'IA) une fois qu'il sera optimisé\n",
    "x_test  = data_test[['petal_length','petal_width']]\n",
    "y_test  = data_test[['setosa','versicolor','virginica']]\n",
    "y_test_species = data_test[['species']]\n",
    "\n",
    "print('x_train : ',x_train.shape)\n",
    "display(x_train)\n",
    "print('y_train : ',y_train.shape,'y_train_species : ',y_train_species.shape)\n",
    "display(y_train, y_train_species)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94b4f9b-46d6-4988-a3f3-ab75734b6ffa",
   "metadata": {},
   "source": [
    "#### 3.2.c. Adaptation des données à la régression logistique par le réseau de neurones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "70779f6b-4820-427f-a2ce-96ac775809a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_69d28\">\n",
       "  <caption>Training set après normalisation (avec scikit-learn):</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_69d28_level0_col0\" class=\"col_heading level0 col0\" >petal_length</th>\n",
       "      <th id=\"T_69d28_level0_col1\" class=\"col_heading level0 col1\" >petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_69d28_level0_row0\" class=\"row_heading level0 row0\" >count</th>\n",
       "      <td id=\"T_69d28_row0_col0\" class=\"data row0 col0\" >120.00</td>\n",
       "      <td id=\"T_69d28_row0_col1\" class=\"data row0 col1\" >120.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_69d28_level0_row1\" class=\"row_heading level0 row1\" >mean</th>\n",
       "      <td id=\"T_69d28_row1_col0\" class=\"data row1 col0\" >0.00</td>\n",
       "      <td id=\"T_69d28_row1_col1\" class=\"data row1 col1\" >-0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_69d28_level0_row2\" class=\"row_heading level0 row2\" >std</th>\n",
       "      <td id=\"T_69d28_row2_col0\" class=\"data row2 col0\" >1.00</td>\n",
       "      <td id=\"T_69d28_row2_col1\" class=\"data row2 col1\" >1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_69d28_level0_row3\" class=\"row_heading level0 row3\" >min</th>\n",
       "      <td id=\"T_69d28_row3_col0\" class=\"data row3 col0\" >-1.64</td>\n",
       "      <td id=\"T_69d28_row3_col1\" class=\"data row3 col1\" >-1.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_69d28_level0_row4\" class=\"row_heading level0 row4\" >25%</th>\n",
       "      <td id=\"T_69d28_row4_col0\" class=\"data row4 col0\" >-1.29</td>\n",
       "      <td id=\"T_69d28_row4_col1\" class=\"data row4 col1\" >-1.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_69d28_level0_row5\" class=\"row_heading level0 row5\" >50%</th>\n",
       "      <td id=\"T_69d28_row5_col0\" class=\"data row5 col0\" >0.31</td>\n",
       "      <td id=\"T_69d28_row5_col1\" class=\"data row5 col1\" >0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_69d28_level0_row6\" class=\"row_heading level0 row6\" >75%</th>\n",
       "      <td id=\"T_69d28_row6_col0\" class=\"data row6 col0\" >0.71</td>\n",
       "      <td id=\"T_69d28_row6_col1\" class=\"data row6 col1\" >0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_69d28_level0_row7\" class=\"row_heading level0 row7\" >max</th>\n",
       "      <td id=\"T_69d28_row7_col0\" class=\"data row7 col0\" >1.74</td>\n",
       "      <td id=\"T_69d28_row7_col1\" class=\"data row7 col1\" >1.66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f7faa8e3790>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_61b27\">\n",
       "  <caption>Test set after après normalisation (avec scikit-learn):</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_61b27_level0_col0\" class=\"col_heading level0 col0\" >petal_length</th>\n",
       "      <th id=\"T_61b27_level0_col1\" class=\"col_heading level0 col1\" >petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_61b27_level0_row0\" class=\"row_heading level0 row0\" >count</th>\n",
       "      <td id=\"T_61b27_row0_col0\" class=\"data row0 col0\" >30.00</td>\n",
       "      <td id=\"T_61b27_row0_col1\" class=\"data row0 col1\" >30.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_61b27_level0_row1\" class=\"row_heading level0 row1\" >mean</th>\n",
       "      <td id=\"T_61b27_row1_col0\" class=\"data row1 col0\" >-0.27</td>\n",
       "      <td id=\"T_61b27_row1_col1\" class=\"data row1 col1\" >-0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_61b27_level0_row2\" class=\"row_heading level0 row2\" >std</th>\n",
       "      <td id=\"T_61b27_row2_col0\" class=\"data row2 col0\" >1.02</td>\n",
       "      <td id=\"T_61b27_row2_col1\" class=\"data row2 col1\" >1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_61b27_level0_row3\" class=\"row_heading level0 row3\" >min</th>\n",
       "      <td id=\"T_61b27_row3_col0\" class=\"data row3 col0\" >-1.52</td>\n",
       "      <td id=\"T_61b27_row3_col1\" class=\"data row3 col1\" >-1.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_61b27_level0_row4\" class=\"row_heading level0 row4\" >25%</th>\n",
       "      <td id=\"T_61b27_row4_col0\" class=\"data row4 col0\" >-1.35</td>\n",
       "      <td id=\"T_61b27_row4_col1\" class=\"data row4 col1\" >-1.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_61b27_level0_row5\" class=\"row_heading level0 row5\" >50%</th>\n",
       "      <td id=\"T_61b27_row5_col0\" class=\"data row5 col0\" >0.08</td>\n",
       "      <td id=\"T_61b27_row5_col1\" class=\"data row5 col1\" >0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_61b27_level0_row6\" class=\"row_heading level0 row6\" >75%</th>\n",
       "      <td id=\"T_61b27_row6_col0\" class=\"data row6 col0\" >0.61</td>\n",
       "      <td id=\"T_61b27_row6_col1\" class=\"data row6 col1\" >0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_61b27_level0_row7\" class=\"row_heading level0 row7\" >max</th>\n",
       "      <td id=\"T_61b27_row7_col0\" class=\"data row7 col0\" >1.23</td>\n",
       "      <td id=\"T_61b27_row7_col1\" class=\"data row7 col1\" >1.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f7faa78d160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(x_train.values)\n",
    "x_trainS = scaler.transform(x_train.values) #returns a numpy array\n",
    "x_testS = scaler.transform(x_test.values) #returns a numpy array\n",
    "x_trainD = pd.DataFrame(x_trainS, columns=x_train.columns, index=x_train.index)\n",
    "x_testD = pd.DataFrame(x_testS, columns=x_test.columns, index=x_test.index)\n",
    "display(x_trainD.describe().style.format(\"{0:.2f}\").set_caption(\"Training set après normalisation (avec scikit-learn):\"))\n",
    "display(x_testD.describe().style.format(\"{0:.2f}\").set_caption(\"Test set after après normalisation (avec scikit-learn):\"))\n",
    "x_train = x_trainS\n",
    "x_test = x_testS\n",
    "del x_trainD, x_testD, x_trainS, x_testS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95d9cd3-ebdc-4bb3-bb75-640600b7d2de",
   "metadata": {},
   "source": [
    "### 3.3. Modèle de réseau de neurones (ANN = artificial neural network)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7111b5f-5db1-457a-a4ed-a93902334ebe",
   "metadata": {},
   "source": [
    "#### 3.3.a. Définition du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "776ea4a4-a5f4-4898-886d-cec103569b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(NE): #NE = nombre de neurones d'entrée\n",
    "    \n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Input(NE, name='iLayer'))\n",
    "    model.add(keras.layers.Dense(7, activation='relu', name='hLayer1'))\n",
    "    model.add(keras.layers.Dense(5, activation='relu', name='hLayer2'))\n",
    "    model.add(keras.layers.Dense(3, activation='softmax', name='oLayer'))\n",
    "    \n",
    "    model.compile(optimizer = 'adam',\n",
    "                  loss      = 'categorical_crossentropy',\n",
    "                  metrics   = ['accuracy'] )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32938fc-ef05-46d6-9f26-80a727d0bc8f",
   "metadata": {},
   "source": [
    "#### 3.3.b. Apprentissage supervisé du réseau de neurones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "877b00e0-83b3-4540-ad09-ffa631fde346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train. Structure (shape) : (120, 2)\n",
      "x_test. Structure (shape) : (30, 2)\n",
      "y_train. Structure (shape) : (120, 3)\n",
      "y_test. Structure (shape) : (30, 3)\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hLayer1 (Dense)              (None, 7)                 21        \n",
      "_________________________________________________________________\n",
      "hLayer2 (Dense)              (None, 5)                 40        \n",
      "_________________________________________________________________\n",
      "oLayer (Dense)               (None, 3)                 18        \n",
      "=================================================================\n",
      "Total params: 79\n",
      "Trainable params: 79\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/700\n",
      "24/24 [==============================] - 1s 25ms/step - loss: 1.1305 - accuracy: 0.0765 - val_loss: 1.0706 - val_accuracy: 0.1000\n",
      "Epoch 2/700\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 1.0954 - accuracy: 0.2573 - val_loss: 1.0274 - val_accuracy: 0.4333\n",
      "Epoch 3/700\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 1.0576 - accuracy: 0.3323 - val_loss: 0.9818 - val_accuracy: 0.4333\n",
      "Epoch 4/700\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 1.0107 - accuracy: 0.3720 - val_loss: 0.9385 - val_accuracy: 0.4667\n",
      "Epoch 5/700\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.9886 - accuracy: 0.3622 - val_loss: 0.8919 - val_accuracy: 0.5000\n",
      "Epoch 6/700\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.9209 - accuracy: 0.4547 - val_loss: 0.8450 - val_accuracy: 0.5333\n",
      "Epoch 7/700\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.9385 - accuracy: 0.4689 - val_loss: 0.8002 - val_accuracy: 0.6000\n",
      "Epoch 8/700\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.8847 - accuracy: 0.5970 - val_loss: 0.7538 - val_accuracy: 0.6333\n",
      "Epoch 9/700\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.8462 - accuracy: 0.6361 - val_loss: 0.7146 - val_accuracy: 0.7000\n",
      "Epoch 10/700\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.8184 - accuracy: 0.6246 - val_loss: 0.6818 - val_accuracy: 0.7333\n",
      "Epoch 11/700\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.7679 - accuracy: 0.7561 - val_loss: 0.6527 - val_accuracy: 0.7333\n",
      "Epoch 12/700\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.8169 - accuracy: 0.7508 - val_loss: 0.6270 - val_accuracy: 0.8000\n",
      "Epoch 13/700\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.7497 - accuracy: 0.8289 - val_loss: 0.5934 - val_accuracy: 0.9333\n",
      "Epoch 14/700\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.7649 - accuracy: 0.9061 - val_loss: 0.5474 - val_accuracy: 1.0000\n",
      "Epoch 15/700\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.6462 - accuracy: 0.9015 - val_loss: 0.5220 - val_accuracy: 1.0000\n",
      "Epoch 16/700\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.6394 - accuracy: 0.9005 - val_loss: 0.4914 - val_accuracy: 1.0000\n",
      "Epoch 17/700\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.5989 - accuracy: 0.9096 - val_loss: 0.4685 - val_accuracy: 1.0000\n",
      "Epoch 18/700\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.6257 - accuracy: 0.9032 - val_loss: 0.4417 - val_accuracy: 1.0000\n",
      "Epoch 19/700\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.5579 - accuracy: 0.8873 - val_loss: 0.4223 - val_accuracy: 1.0000\n",
      "Epoch 20/700\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.5290 - accuracy: 0.9067 - val_loss: 0.3973 - val_accuracy: 1.0000\n",
      "Epoch 21/700\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.5283 - accuracy: 0.8872 - val_loss: 0.3808 - val_accuracy: 1.0000\n",
      "Epoch 22/700\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.4963 - accuracy: 0.9524 - val_loss: 0.3580 - val_accuracy: 1.0000\n",
      "Epoch 23/700\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.4725 - accuracy: 0.9060 - val_loss: 0.3488 - val_accuracy: 1.0000\n",
      "Epoch 24/700\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.4445 - accuracy: 0.9647 - val_loss: 0.3306 - val_accuracy: 1.0000\n",
      "Epoch 25/700\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.4391 - accuracy: 0.9514 - val_loss: 0.3199 - val_accuracy: 1.0000\n",
      "Epoch 26/700\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.4415 - accuracy: 0.9360 - val_loss: 0.3041 - val_accuracy: 1.0000\n",
      "Epoch 27/700\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.4313 - accuracy: 0.9124 - val_loss: 0.2938 - val_accuracy: 1.0000\n",
      "Epoch 28/700\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.3812 - accuracy: 0.9800 - val_loss: 0.2781 - val_accuracy: 1.0000\n",
      "Epoch 29/700\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3831 - accuracy: 0.9516 - val_loss: 0.2693 - val_accuracy: 0.9667\n",
      "Epoch 30/700\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.4139 - accuracy: 0.9390 - val_loss: 0.2609 - val_accuracy: 0.9667\n",
      "Epoch 31/700\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.3177 - accuracy: 0.9823 - val_loss: 0.2491 - val_accuracy: 0.9667\n",
      "Epoch 32/700\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.3461 - accuracy: 0.9541 - val_loss: 0.2427 - val_accuracy: 0.9667\n",
      "Epoch 33/700\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 0.3095 - accuracy: 0.9753 - val_loss: 0.2283 - val_accuracy: 0.9667\n",
      "Epoch 34/700\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3255 - accuracy: 0.9607 - val_loss: 0.2271 - val_accuracy: 0.9333\n",
      "Epoch 35/700\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2881 - accuracy: 0.9580 - val_loss: 0.2155 - val_accuracy: 0.9333\n",
      "Epoch 36/700\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2798 - accuracy: 0.9277 - val_loss: 0.2082 - val_accuracy: 0.9333\n",
      "Epoch 37/700\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.2483 - accuracy: 0.9652 - val_loss: 0.2009 - val_accuracy: 0.9333\n",
      "Epoch 38/700\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.2042 - accuracy: 0.9738 - val_loss: 0.1962 - val_accuracy: 0.9333\n",
      "Epoch 39/700\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 0.2339 - accuracy: 0.9504 - val_loss: 0.1903 - val_accuracy: 0.9333\n",
      "Epoch 40/700\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.2115 - accuracy: 0.9693 - val_loss: 0.1856 - val_accuracy: 0.9333\n",
      "Epoch 41/700\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.1798 - accuracy: 0.9560 - val_loss: 0.1771 - val_accuracy: 0.9333\n",
      "Epoch 42/700\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.2078 - accuracy: 0.9428 - val_loss: 0.1724 - val_accuracy: 0.9333\n",
      "Epoch 43/700\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.1848 - accuracy: 0.9640 - val_loss: 0.1619 - val_accuracy: 0.9333\n",
      "Epoch 44/700\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.1510 - accuracy: 0.9687 - val_loss: 0.1755 - val_accuracy: 0.9333\n",
      "Epoch 45/700\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.1679 - accuracy: 0.9517 - val_loss: 0.1652 - val_accuracy: 0.9333\n",
      "Epoch 46/700\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.1436 - accuracy: 0.9764 - val_loss: 0.1541 - val_accuracy: 0.9333\n",
      "Epoch 47/700\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1500 - accuracy: 0.9563 - val_loss: 0.1613 - val_accuracy: 0.9333\n",
      "Epoch 48/700\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 0.1118 - accuracy: 0.9836 - val_loss: 0.1528 - val_accuracy: 0.9333\n",
      "Epoch 49/700\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1253 - accuracy: 0.9718 - val_loss: 0.1443 - val_accuracy: 0.9333\n",
      "Epoch 50/700\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.1333 - accuracy: 0.9676 - val_loss: 0.1536 - val_accuracy: 0.9333\n",
      "Epoch 51/700\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.1431 - accuracy: 0.9611 - val_loss: 0.1429 - val_accuracy: 0.9333\n",
      "Epoch 52/700\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1147 - accuracy: 0.9624 - val_loss: 0.1494 - val_accuracy: 0.9333\n",
      "Epoch 53/700\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1121 - accuracy: 0.9682 - val_loss: 0.1480 - val_accuracy: 0.9333\n",
      "Epoch 54/700\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1302 - accuracy: 0.9463 - val_loss: 0.1324 - val_accuracy: 0.9333\n",
      "Epoch 55/700\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0927 - accuracy: 0.9799 - val_loss: 0.1291 - val_accuracy: 0.9333\n",
      "Epoch 56/700\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1030 - accuracy: 0.9720 - val_loss: 0.1383 - val_accuracy: 0.9333\n",
      "Epoch 57/700\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0940 - accuracy: 0.9831 - val_loss: 0.1377 - val_accuracy: 0.9333\n",
      "Epoch 58/700\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0764 - accuracy: 0.9870 - val_loss: 0.1280 - val_accuracy: 0.9333\n",
      "Epoch 59/700\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0868 - accuracy: 0.9651 - val_loss: 0.1336 - val_accuracy: 0.9333\n",
      "Epoch 60/700\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 0.1007 - accuracy: 0.9619 - val_loss: 0.1276 - val_accuracy: 0.9333\n",
      "Epoch 61/700\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.1056 - accuracy: 0.9700 - val_loss: 0.1266 - val_accuracy: 0.9333\n",
      "Epoch 62/700\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.0901 - accuracy: 0.9656 - val_loss: 0.1366 - val_accuracy: 0.9333\n",
      "Epoch 63/700\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 0.0783 - accuracy: 0.9809 - val_loss: 0.1287 - val_accuracy: 0.9333\n",
      "Epoch 64/700\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.1530 - accuracy: 0.9309 - val_loss: 0.1268 - val_accuracy: 0.9333\n",
      "Epoch 65/700\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0731 - accuracy: 0.9723 - val_loss: 0.1329 - val_accuracy: 0.9333\n",
      "Epoch 66/700\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0861 - accuracy: 0.9726 - val_loss: 0.1238 - val_accuracy: 0.9333\n",
      "Epoch 67/700\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0750 - accuracy: 0.9851 - val_loss: 0.1166 - val_accuracy: 0.9333\n",
      "Epoch 68/700\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0905 - accuracy: 0.9661 - val_loss: 0.1253 - val_accuracy: 0.9333\n",
      "Epoch 69/700\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0542 - accuracy: 0.9889 - val_loss: 0.1291 - val_accuracy: 0.9333\n",
      "Epoch 70/700\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0904 - accuracy: 0.9704 - val_loss: 0.1285 - val_accuracy: 0.9333\n",
      "Epoch 71/700\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0674 - accuracy: 0.9762 - val_loss: 0.1253 - val_accuracy: 0.9333\n",
      "Epoch 72/700\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.0734 - accuracy: 0.9841 - val_loss: 0.1200 - val_accuracy: 0.9333\n",
      "Epoch 73/700\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.0828 - accuracy: 0.9686 - val_loss: 0.1259 - val_accuracy: 0.9333\n",
      "Epoch 74/700\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.0659 - accuracy: 0.9800 - val_loss: 0.1253 - val_accuracy: 0.9333\n",
      "Epoch 75/700\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0781 - accuracy: 0.9655 - val_loss: 0.1152 - val_accuracy: 0.9333\n",
      "Epoch 76/700\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0814 - accuracy: 0.9664 - val_loss: 0.1230 - val_accuracy: 0.9333\n",
      "Epoch 77/700\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0585 - accuracy: 0.9777 - val_loss: 0.1255 - val_accuracy: 0.9333\n",
      "Epoch 78/700\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0617 - accuracy: 0.9835 - val_loss: 0.1239 - val_accuracy: 0.9333\n",
      "Epoch 79/700\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0798 - accuracy: 0.9648 - val_loss: 0.1216 - val_accuracy: 0.9333\n",
      "Epoch 80/700\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.1006 - accuracy: 0.9606 - val_loss: 0.1236 - val_accuracy: 0.9333\n",
      "Epoch 81/700\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0471 - accuracy: 0.9897 - val_loss: 0.1287 - val_accuracy: 0.9333\n",
      "Epoch 82/700\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.0650 - accuracy: 0.9791 - val_loss: 0.1218 - val_accuracy: 0.9333\n",
      "Epoch 83/700\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.0840 - accuracy: 0.9509 - val_loss: 0.1389 - val_accuracy: 0.9333\n",
      "Epoch 84/700\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0757 - accuracy: 0.9786 - val_loss: 0.1203 - val_accuracy: 0.9333\n",
      "Epoch 85/700\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0456 - accuracy: 0.9864 - val_loss: 0.1253 - val_accuracy: 0.9333\n",
      "Epoch 00085: early stopping\n",
      "\n",
      "Duration :  00:00:19 497ms\n"
     ]
    }
   ],
   "source": [
    "vID.chrono_start()\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
    "print(f\"x_train. Structure (shape) : {x_train.shape}\")\n",
    "print(f\"x_test. Structure (shape) : {x_test.shape}\")\n",
    "print(f\"y_train. Structure (shape) : {y_train.shape}\")\n",
    "print(f\"y_test. Structure (shape) : {y_test.shape}\")\n",
    "ANNmodel=get_model( (2,)) # 2 neurones d'entrée\n",
    "ANNmodel.summary()\n",
    "vID.chrono_start()\n",
    "ANNhistory = ANNmodel.fit(x_train,\n",
    "                    y_train,\n",
    "                    epochs          = 700,\n",
    "                    batch_size      = 5,\n",
    "                    verbose         = 1,\n",
    "                    validation_data = (x_test, y_test),\n",
    "                    callbacks=[es])\n",
    "vID.chrono_show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d916c59d-3cc8-466f-b776-ec09e2038f9a",
   "metadata": {},
   "source": [
    "### 3.4. Évaluation de la précision du réseau de neurones après apprentissage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f927a6-ce28-443a-b4f9-0c47140e51ef",
   "metadata": {},
   "source": [
    "#### 3.4.a. Évaluation numérique globale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fe7d2f5f-14a3-4484-9cc6-69a080e0212b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mx_train / loss      : 0.0682\u001b[0m\n",
      "\u001b[92mx_train/ accurracy  : 0.9750\u001b[0m\n",
      "\n",
      "\u001b[94mx_train / loss      : 0.1253\u001b[0m\n",
      "\u001b[94mx_train/ accurracy  : 0.9333\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "evalANN_on_Train = ANNmodel.evaluate(x_train, y_train, verbose=0)\n",
    "print(f\"{color.GREEN}x_train / loss      : {evalANN_on_Train[0]:5.4f}{color.OFF}\")\n",
    "print(f\"{color.GREEN}x_train/ accurracy  : {evalANN_on_Train[1]:5.4f}{color.OFF}\")\n",
    "print()\n",
    "evalANN_on_Test = ANNmodel.evaluate(x_test, y_test, verbose=0)\n",
    "print(f\"{color.BLUE}x_train / loss      : {evalANN_on_Test[0]:5.4f}{color.OFF}\")\n",
    "print(f\"{color.BLUE}x_train/ accurracy  : {evalANN_on_Test[1]:5.4f}{color.OFF}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5149669f-0ee6-4f8f-9f40-1cb91e4929ad",
   "metadata": {},
   "source": [
    "#### 3.4.b. Comportement du modèle vis-à-vis de chaque espèce d'iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "35c740a5-53e5-4776-8cea-b53af7589366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[92mCatégories uniques d'iris :\u001b[0m ['setosa' 'versicolor' 'virginica']\n",
      "\u001b[1m\u001b[94mTest Set\u001b[0m. Comparaison entre espèce prédite et espèce observée\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>setosa</th>\n",
       "      <th>versicolor</th>\n",
       "      <th>virginica</th>\n",
       "      <th>Espèce prédite</th>\n",
       "      <th>Espèce observée</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.41</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.05</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.96</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.53</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.09</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.00</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.82</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.97</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.96</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.01</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.82</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.88</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.88</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.97</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.98</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.97</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.35</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.05</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.13</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.82</td>\n",
       "      <td>virginica</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.01</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.02</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.01</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.95</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.98</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.97</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.98</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.97</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.15</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.29</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.05</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.29</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.29</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.05</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.98</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.82</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.05</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     setosa  versicolor  virginica Espèce prédite Espèce observée\n",
       "30     1.00        0.00       0.00         setosa          setosa\n",
       "67     0.00        1.00       0.00     versicolor      versicolor\n",
       "105    0.01        0.00       0.99      virginica       virginica\n",
       "16     1.00        0.00       0.00         setosa          setosa\n",
       "119    0.02        0.57       0.41     versicolor       virginica\n",
       "89     0.00        1.00       0.00     versicolor      versicolor\n",
       "84     0.01        0.94       0.05     versicolor      versicolor\n",
       "128    0.01        0.00       0.99      virginica       virginica\n",
       "64     0.00        1.00       0.00     versicolor      versicolor\n",
       "114    0.01        0.00       0.99      virginica       virginica\n",
       "41     1.00        0.00       0.00         setosa          setosa\n",
       "87     0.00        0.99       0.00     versicolor      versicolor\n",
       "140    0.01        0.00       0.99      virginica       virginica\n",
       "146    0.01        0.02       0.96      virginica       virginica\n",
       "26     0.99        0.01       0.00         setosa          setosa\n",
       "82     0.00        1.00       0.00     versicolor      versicolor\n",
       "133    0.02        0.45       0.53      virginica       virginica\n",
       "76     0.01        0.91       0.09     versicolor      versicolor\n",
       "98     0.05        0.94       0.00     versicolor      versicolor\n",
       "81     0.00        1.00       0.00     versicolor      versicolor\n",
       "20     1.00        0.00       0.00         setosa          setosa\n",
       "138    0.02        0.16       0.82      virginica       virginica\n",
       "0      1.00        0.00       0.00         setosa          setosa\n",
       "45     1.00        0.00       0.00         setosa          setosa\n",
       "24     0.99        0.01       0.00         setosa          setosa\n",
       "132    0.01        0.00       0.99      virginica       virginica\n",
       "115    0.01        0.00       0.99      virginica       virginica\n",
       "9      1.00        0.00       0.00         setosa          setosa\n",
       "121    0.01        0.01       0.97      virginica       virginica\n",
       "79     0.01        0.99       0.00     versicolor      versicolor\n",
       "99     0.00        1.00       0.00     versicolor      versicolor\n",
       "129    0.02        0.03       0.96      virginica       virginica\n",
       "29     1.00        0.00       0.00         setosa          setosa\n",
       "53     0.00        1.00       0.00     versicolor      versicolor\n",
       "14     1.00        0.00       0.00         setosa          setosa\n",
       "58     0.00        0.98       0.01     versicolor      versicolor\n",
       "33     1.00        0.00       0.00         setosa          setosa\n",
       "126    0.02        0.16       0.82      virginica       virginica\n",
       "127    0.02        0.10       0.88      virginica       virginica\n",
       "104    0.01        0.00       0.99      virginica       virginica\n",
       "123    0.02        0.10       0.88      virginica       virginica\n",
       "103    0.01        0.01       0.97      virginica       virginica\n",
       "130    0.01        0.00       0.99      virginica       virginica\n",
       "57     0.02        0.98       0.00     versicolor      versicolor\n",
       "73     0.00        0.99       0.01     versicolor      versicolor\n",
       "111    0.01        0.01       0.98      virginica       virginica\n",
       "42     1.00        0.00       0.00         setosa          setosa\n",
       "23     0.99        0.01       0.00         setosa          setosa\n",
       "142    0.01        0.02       0.97      virginica       virginica\n",
       "107    0.01        0.00       0.99      virginica       virginica\n",
       "46     1.00        0.00       0.00         setosa          setosa\n",
       "7      1.00        0.00       0.00         setosa          setosa\n",
       "106    0.03        0.62       0.35     versicolor       virginica\n",
       "112    0.01        0.00       0.99      virginica       virginica\n",
       "51     0.01        0.94       0.05     versicolor      versicolor\n",
       "86     0.01        0.85       0.13     versicolor      versicolor\n",
       "94     0.00        1.00       0.00     versicolor      versicolor\n",
       "88     0.00        1.00       0.00     versicolor      versicolor\n",
       "96     0.00        1.00       0.00     versicolor      versicolor\n",
       "5      0.99        0.01       0.00         setosa          setosa\n",
       "118    0.00        0.00       1.00      virginica       virginica\n",
       "27     1.00        0.00       0.00         setosa          setosa\n",
       "70     0.02        0.16       0.82      virginica      versicolor\n",
       "22     1.00        0.00       0.00         setosa          setosa\n",
       "15     0.99        0.00       0.00         setosa          setosa\n",
       "117    0.00        0.00       1.00      virginica       virginica\n",
       "135    0.01        0.00       0.99      virginica       virginica\n",
       "75     0.00        0.98       0.01     versicolor      versicolor\n",
       "61     0.01        0.97       0.02     versicolor      versicolor\n",
       "65     0.00        0.98       0.01     versicolor      versicolor\n",
       "139    0.01        0.00       0.99      virginica       virginica\n",
       "38     1.00        0.00       0.00         setosa          setosa\n",
       "32     1.00        0.00       0.00         setosa          setosa\n",
       "21     0.99        0.00       0.00         setosa          setosa\n",
       "149    0.01        0.04       0.95      virginica       virginica\n",
       "90     0.00        1.00       0.00     versicolor      versicolor\n",
       "145    0.01        0.00       0.99      virginica       virginica\n",
       "43     0.99        0.01       0.00         setosa          setosa\n",
       "100    0.00        0.00       1.00      virginica       virginica\n",
       "12     1.00        0.00       0.00         setosa          setosa\n",
       "108    0.01        0.01       0.98      virginica       virginica\n",
       "39     1.00        0.00       0.00         setosa          setosa\n",
       "74     0.00        1.00       0.00     versicolor      versicolor\n",
       "101    0.01        0.02       0.97      virginica       virginica\n",
       "93     0.02        0.98       0.00     versicolor      versicolor\n",
       "60     0.01        0.99       0.00     versicolor      versicolor\n",
       "131    0.01        0.00       0.99      virginica       virginica\n",
       "113    0.01        0.01       0.98      virginica       virginica\n",
       "25     1.00        0.00       0.00         setosa          setosa\n",
       "148    0.01        0.00       0.99      virginica       virginica\n",
       "10     1.00        0.00       0.00         setosa          setosa\n",
       "137    0.01        0.01       0.97      virginica       virginica\n",
       "97     0.00        1.00       0.00     versicolor      versicolor\n",
       "85     0.02        0.84       0.15     versicolor      versicolor\n",
       "52     0.02        0.69       0.29     versicolor      versicolor\n",
       "63     0.01        0.94       0.05     versicolor      versicolor\n",
       "2      1.00        0.00       0.00         setosa          setosa\n",
       "72     0.02        0.69       0.29     versicolor      versicolor\n",
       "34     1.00        0.00       0.00         setosa          setosa\n",
       "136    0.01        0.00       0.99      virginica       virginica\n",
       "6      1.00        0.00       0.00         setosa          setosa\n",
       "44     0.98        0.02       0.00         setosa          setosa\n",
       "56     0.02        0.69       0.29     versicolor      versicolor\n",
       "4      1.00        0.00       0.00         setosa          setosa\n",
       "49     1.00        0.00       0.00         setosa          setosa\n",
       "78     0.01        0.94       0.05     versicolor      versicolor\n",
       "69     0.00        1.00       0.00     versicolor      versicolor\n",
       "92     0.00        1.00       0.00     versicolor      versicolor\n",
       "144    0.01        0.00       0.99      virginica       virginica\n",
       "109    0.00        0.00       1.00      virginica       virginica\n",
       "110    0.01        0.01       0.98      virginica       virginica\n",
       "102    0.01        0.00       0.99      virginica       virginica\n",
       "122    0.01        0.00       0.99      virginica       virginica\n",
       "13     1.00        0.00       0.00         setosa          setosa\n",
       "47     1.00        0.00       0.00         setosa          setosa\n",
       "28     1.00        0.00       0.00         setosa          setosa\n",
       "80     0.00        1.00       0.00     versicolor      versicolor\n",
       "134    0.02        0.16       0.82      virginica       virginica\n",
       "68     0.01        0.94       0.05     versicolor      versicolor\n",
       "124    0.01        0.00       0.99      virginica       virginica"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'erreurs : 3\n",
      "\n",
      "\u001b[1m\u001b[91mTest Set\u001b[0m. Comparaison entre espèce prédite et espèce observée.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>setosa</th>\n",
       "      <th>versicolor</th>\n",
       "      <th>virginica</th>\n",
       "      <th>Espèce prédite</th>\n",
       "      <th>Espèce observée</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.05</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.08</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.05</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.82</td>\n",
       "      <td>virginica</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.75</td>\n",
       "      <td>virginica</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.03</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.97</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.98</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     setosa  versicolor  virginica Espèce prédite Espèce observée\n",
       "1      1.00        0.00       0.00         setosa          setosa\n",
       "3      1.00        0.00       0.00         setosa          setosa\n",
       "8      1.00        0.00       0.00         setosa          setosa\n",
       "11     1.00        0.00       0.00         setosa          setosa\n",
       "17     1.00        0.00       0.00         setosa          setosa\n",
       "18     0.99        0.01       0.00         setosa          setosa\n",
       "19     1.00        0.00       0.00         setosa          setosa\n",
       "31     0.99        0.00       0.00         setosa          setosa\n",
       "35     1.00        0.00       0.00         setosa          setosa\n",
       "36     1.00        0.00       0.00         setosa          setosa\n",
       "37     1.00        0.00       0.00         setosa          setosa\n",
       "40     1.00        0.00       0.00         setosa          setosa\n",
       "48     1.00        0.00       0.00         setosa          setosa\n",
       "50     0.01        0.94       0.05     versicolor      versicolor\n",
       "54     0.01        0.91       0.08     versicolor      versicolor\n",
       "55     0.00        0.99       0.01     versicolor      versicolor\n",
       "59     0.00        1.00       0.00     versicolor      versicolor\n",
       "62     0.00        1.00       0.00     versicolor      versicolor\n",
       "66     0.01        0.94       0.05     versicolor      versicolor\n",
       "71     0.00        1.00       0.00     versicolor      versicolor\n",
       "77     0.02        0.15       0.82      virginica      versicolor\n",
       "83     0.02        0.23       0.75      virginica      versicolor\n",
       "91     0.01        0.96       0.03     versicolor      versicolor\n",
       "95     0.00        1.00       0.00     versicolor      versicolor\n",
       "116    0.01        0.01       0.97      virginica       virginica\n",
       "120    0.01        0.00       0.99      virginica       virginica\n",
       "125    0.01        0.00       0.98      virginica       virginica\n",
       "141    0.01        0.00       0.99      virginica       virginica\n",
       "143    0.01        0.00       0.99      virginica       virginica\n",
       "147    0.01        0.01       0.98      virginica       virginica"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'erreurs : 2\n"
     ]
    }
   ],
   "source": [
    "usp = dfi['species'].unique()\n",
    "print(f\"{color.BOLD}{color.GREEN}Catégories uniques d'iris :{color.OFF} {usp}\")\n",
    "# cette correspondance élément 0 <-> setosa ; élément 1 <-> versicolor ; élément 2 <-> virginica\n",
    "# va servir à transformer les probabilités les plus élevées en espèce d'iris\n",
    "\n",
    "y_train_hat=ANNmodel.predict(x_train)\n",
    "ytr_hD = pd.DataFrame(y_train_hat, columns=usp, index=y_train.index)\n",
    "# argmax renvoie l'indice de la valeur maximale selon un axe (0 = ligne / 1 = colonne)\n",
    "# ça va ici nous renvoyer pour chaque ligne le numéro de la colonne qui contient la plus grande valeur de probabilité\n",
    "# on convertit maintenant 0, 1 & 2 en espèce d'iris\n",
    "iris_tr_hat = usp[np.argmax(y_train_hat,axis=1)]\n",
    "# on ajoute cette colonne au dataframe ytr_hD\n",
    "ytr_hD['Espèce prédite'] = pd.DataFrame(iris_tr_hat, index=y_train.index)\n",
    "ytr_hD['Espèce observée'] = pd.DataFrame(y_train_species, index=y_train.index)\n",
    "print(f\"{color.BOLD}{color.BLUE}Test Set{color.OFF}. Comparaison entre espèce prédite et espèce observée\")\n",
    "pd.set_option('display.max_rows', None) #on veut afficher toutes les lignes des DataFrames\n",
    "pd.options.display.float_format = '{:,.2f}'.format #on formatte les probabilités, sinon c'est illisible\n",
    "display(ytr_hD)\n",
    "pd.set_option('display.max_rows', 10) #reset de l'affichage: 5 premières et 5 dernières lignes\n",
    "pd.options.display.float_format = None #reset de l'affichage: format standard \n",
    "diff_Pred_Obs=np.where(ytr_hD['Espèce prédite'] == ytr_hD['Espèce observée'], 0, 1)\n",
    "print(f\"Nombre d'erreurs : {np.sum(diff_Pred_Obs)}\")\n",
    "\n",
    "print()\n",
    "y_test_hat=ANNmodel.predict(x_test)\n",
    "ytt_hD = pd.DataFrame(y_test_hat, columns=usp, index=y_test.index)\n",
    "# argmax renvoie l'indice de la valeur maximale selon un axe (0 = ligne / 1 = colonne)\n",
    "# ça va ici nous renvoyer pour chaque ligne le numéro de la colonne qui contient la plus grande valeur de probabilité\n",
    "# on convertit maintenant 0, 1 & 2 en espèce d'iris\n",
    "iris_tt_hat = usp[np.argmax(y_test_hat,axis=1)]\n",
    "# on ajoute cette colonne au dataframe ytt_hD\n",
    "ytt_hD['Espèce prédite'] = pd.DataFrame(iris_tt_hat, index=y_test.index)\n",
    "ytt_hD['Espèce observée'] = pd.DataFrame(y_test_species, index=y_test.index)\n",
    "print(f\"{color.BOLD}{color.RED}Test Set{color.OFF}. Comparaison entre espèce prédite et espèce observée.\")\n",
    "pd.set_option('display.max_rows', None) #on veut afficher toutes les lignes des DataFrames\n",
    "pd.options.display.float_format = '{:,.2f}'.format #on formatte les probabilités, sinon c'est illisible\n",
    "display(ytt_hD)\n",
    "pd.set_option('display.max_rows', 10) #reset de l'affichage: 5 premières et 5 dernières lignes\n",
    "pd.options.display.float_format = None #reset de l'affichage: \n",
    "diff_Pred_Obs=np.where(ytt_hD['Espèce prédite'] == ytt_hD['Espèce observée'], 0, 1)\n",
    "print(f\"Nombre d'erreurs : {np.sum(diff_Pred_Obs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55fe30e-ce3d-49bf-b488-6fe9bff3291b",
   "metadata": {},
   "source": [
    "#### 3.4.c. Bilan de la performance du modèle prédictif sous forme de matrice de confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "866bd474-9393-4311-b165-0f66d021e221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set. Matrice de confusion\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set. Matrice de confusion\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm_labels = dfi['species'].unique()\n",
    "print(\"Training set. Matrice de confusion\")\n",
    "cm_tr = confusion_matrix(np.argmax(y_train.to_numpy(),axis=1), np.argmax(y_train_hat,axis=1))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_tr, display_labels=cm_labels)\n",
    "disp.plot(cmap=plt.cm.Blues) #ici cm = diminutif de colormap dans matplotlib\n",
    "plt.show()\n",
    "print(\"Test set. Matrice de confusion\")\n",
    "cm_tt = confusion_matrix(np.argmax(y_test.to_numpy(),axis=1), np.argmax(y_test_hat,axis=1))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_tt, display_labels=cm_labels)\n",
    "disp.plot(cmap=plt.cm.Blues) #ici cm = diminutif de colormap dans matplotlib\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f1edc9-8140-4039-9755-35e9a09d277d",
   "metadata": {},
   "source": [
    "### Bilan de la troisième partie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "af354bcb",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Fin à:** Monday 30 May 2022, 14:16:36  \n",
       "**Durée:** 00:20:41 473ms"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<p style=\"text-align: center\"><img width=\"800px\" src=\"./svg/logoEnd.svg\" style=\"margin-left:auto; margin-right:auto\"></img></p>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vID.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fad06d-6413-4793-b945-a7d707839fee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
