{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8de690ce-49d6-4387-b242-fe36280ca9dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "h1, h2, h3, h4, h5, h6 {\n",
       "  font-family: Verdana, \"DejaVu Sans\", \"Bitstream Vera Sans\", Geneva, sans-serif;\n",
       "  font-weight: bold;\n",
       "}\n",
       "body {\n",
       "  font-family: Verdana, \"DejaVu Sans\", \"Bitstream Vera Sans\", Geneva, sans-serif;\n",
       "  font-weight: 200;\n",
       "}\n",
       "h1 {\n",
       "  border: 0 solid #333;\n",
       "  padding: 30px ;\n",
       "  color: white;\n",
       "  background: #b11d01;\n",
       "  text-align: center;\n",
       "}\n",
       "h2 {\n",
       "  border: 3px solid #333;\n",
       "  padding: 18px ;\n",
       "  color: #b11d01;\n",
       "  background: #ffffff;\n",
       "  text-align: center;\n",
       "}\n",
       "h3 {\n",
       "  border: 0 solid #333;\n",
       "  padding: 12px ;\n",
       "  color: #000000;\n",
       "  background: #c1c1c1;\n",
       "  text-align: left;\n",
       "}\n",
       "h4 {\n",
       "  border: 0 solid #333;\n",
       "  padding: 2px ;\n",
       "  color: #000000;\n",
       "  background: #d9fffc;\n",
       "  text-align: left;\n",
       "}\n",
       "h5 {\n",
       "  border: 1px solid #333;\n",
       "  padding: 2px ;\n",
       "  color: #000000;\n",
       "  background: #ffffff;\n",
       "  text-align: left;\n",
       "}\n",
       ".warn {    \n",
       "    background-color: #fcf2f2;\n",
       "    border-color: #dFb5b4;\n",
       "    border-left: 5px solid #dfb5b4;\n",
       "    padding: 0.5em;\n",
       "    font-weight: 200;\n",
       "    }\n",
       ".rq {    \n",
       "    background-color: #e2e2e2;\n",
       "    border-color: #969696;\n",
       "    border-left: 5px solid #969696;\n",
       "    padding: 0.5em;\n",
       "    font-weight: 200;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Début à:** Thursday 03 November 2022, 21:41:30  \n",
       "**Hostname:** localhost.localdomain (Linux)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<p style=\"text-align: center\"><img width=\"800px\" src=\"../config/svg/logoDebut.svg\" style=\"margin-left:auto; margin-right:auto\"/></p>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "cwd0 = '../config/'\n",
    "sys.path.append(cwd0)\n",
    "\n",
    "import visualID as vID\n",
    "from visualID import color\n",
    "vID.init(cwd0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2f60c2-8759-4019-8dea-b692e73eaee6",
   "metadata": {},
   "source": [
    "### **Exercice.** Apprentissage supervisé (*supervised Machine Learning*) appliqué à la classification.<br>Corrigé\n",
    "\n",
    "On a développé dans le cours un algorithme de reconnaissance basé sur deux caractéristiques, les **longueur et largeur des pétales** d'iris. L'exercice qui est proposé ici vise à développer un algorithme capable d'établir une corrélation plus complexe, en prenant simultanément en compte les **longueurs et largeurs des pétales et des sépales**.\n",
    "\n",
    "<p><img width=\"450px\" src=\"../DS4B-svg/IA-petales-sepales.png\" style=\"margin-left:auto; margin-right:auto; display: block;\" id=\"img_IA_jpc\"/></p>  \n",
    "\n",
    "Et on va voir que ça permet effectivement de diminuer l'erreur commise. On conviendra que ça devient plus compliqué pour nos cerveaux de rechercher si les corrélations croisées, reportées dans la figure ci-dessous, permettent une meilleure classification. C'est pour ce type de tâche, au-delà de corrélations simples, que l'utilisation de ces algorithmes prend tout son sens. \n",
    "\n",
    "<div class=\"warn\">\n",
    "\n",
    "**<span style=\"color:red\">Vous êtes encouragés à \"tricher\" &#128578; ! </span>**, c'est-à-dire à vous inspirer du [notebook de cours](../DS4B-Iris3.ipynb), dont le code n'a qu'à être légèrement adapté pour accepter quatre informations en entrée au lieu de deux seulement.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02aa070-ddf4-4bb4-bb26-5043ee7ca53f",
   "metadata": {},
   "source": [
    "#### Importation des modules utiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b6568ba3-8b12-4725-a890-132a9de260b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exécutez cette cellule, sans la modifier\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib as mp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59355df4-7b76-4a77-a204-13008cc96dc9",
   "metadata": {},
   "source": [
    "#### **Exercice 1.** Lecture, analyse et adaptation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7334ed83-f6aa-4f7e-b6a1-7e49b8b9da66",
   "metadata": {},
   "source": [
    "##### **1.** Lecture de la base de données qui ont été adaptées au problème"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef2fe4da-b86e-4c95-8f97-84f8c0f56215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dfi. Structure (shape) :(150, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "      <th>setosa</th>\n",
       "      <th>versicolor</th>\n",
       "      <th>virginica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>virginica</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width    species  setosa  \\\n",
       "0             5.1          3.5           1.4          0.2     setosa     1.0   \n",
       "1             4.9          3.0           1.4          0.2     setosa     1.0   \n",
       "2             4.7          3.2           1.3          0.2     setosa     1.0   \n",
       "3             4.6          3.1           1.5          0.2     setosa     1.0   \n",
       "4             5.0          3.6           1.4          0.2     setosa     1.0   \n",
       "..            ...          ...           ...          ...        ...     ...   \n",
       "145           6.7          3.0           5.2          2.3  virginica     0.0   \n",
       "146           6.3          2.5           5.0          1.9  virginica     0.0   \n",
       "147           6.5          3.0           5.2          2.0  virginica     0.0   \n",
       "148           6.2          3.4           5.4          2.3  virginica     0.0   \n",
       "149           5.9          3.0           5.1          1.8  virginica     0.0   \n",
       "\n",
       "     versicolor  virginica  \n",
       "0           0.0        0.0  \n",
       "1           0.0        0.0  \n",
       "2           0.0        0.0  \n",
       "3           0.0        0.0  \n",
       "4           0.0        0.0  \n",
       "..          ...        ...  \n",
       "145         0.0        1.0  \n",
       "146         0.0        1.0  \n",
       "147         0.0        1.0  \n",
       "148         0.0        1.0  \n",
       "149         0.0        1.0  \n",
       "\n",
       "[150 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# exécutez cette commande, sans la modifier\n",
    "dfi=pd.read_csv('../DS4B-iris-data/iris_ohe.csv', sep=\"\\t\") #les colonnes sont séparées par des tabulations\n",
    "print(f\"Dfi. Structure (shape) :{dfi.shape}\")\n",
    "\n",
    "# ajouter ci-dessous la commande permettant d'afficher le dataframe dfi - ne pas utiliser print()\n",
    "display(dfi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139cdc56-49f8-4775-abb6-1e9b2ff1b292",
   "metadata": {},
   "source": [
    "##### **2.** Séparation des données en deux sous-ensembles d'apprentissage et de test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005db419-4aa4-4433-95ab-425b265c2e6b",
   "metadata": {},
   "source": [
    "Séparer le jeu de données stocké dans `dfi` en deux sous-ensembles :\n",
    "- un jeu de données d'apprentissage (80% des données de `dfi`)\n",
    "- un jeu de données de test, indépendantes du jeu de données d'apprentissage (20% des données de `dfi`) \n",
    "\n",
    "On définira 4 nouveaux dataframes, `x_train`, `x_test`, `y_train`, `y_test` qui ont pour but d'entraîner et de tester un réseau de neurones conçu pour identifier un type d'iris sur la base de 4 descripteurs : longueur et largeur des pétales & longueur et largeur des sépales. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0470f71-6f34-4ccf-9e56-836928e32004",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train :  (120, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>7.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>7.3</td>\n",
       "      <td>2.9</td>\n",
       "      <td>6.3</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>6.1</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.9</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>6.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>6.2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>6.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.9</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width\n",
       "122           7.7          2.8           6.7          2.0\n",
       "107           7.3          2.9           6.3          1.8\n",
       "63            6.1          2.9           4.7          1.4\n",
       "103           6.3          2.9           5.6          1.8\n",
       "149           5.9          3.0           5.1          1.8\n",
       "..            ...          ...           ...          ...\n",
       "100           6.3          3.3           6.0          2.5\n",
       "43            5.0          3.5           1.6          0.6\n",
       "141           6.9          3.1           5.1          2.3\n",
       "68            6.2          2.2           4.5          1.5\n",
       "143           6.8          3.2           5.9          2.3\n",
       "\n",
       "[120 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train :  (120, 3) y_train_species :  (120, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>setosa</th>\n",
       "      <th>versicolor</th>\n",
       "      <th>virginica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     setosa  versicolor  virginica\n",
       "122     0.0         0.0        1.0\n",
       "107     0.0         0.0        1.0\n",
       "63      0.0         1.0        0.0\n",
       "103     0.0         0.0        1.0\n",
       "149     0.0         0.0        1.0\n",
       "..      ...         ...        ...\n",
       "100     0.0         0.0        1.0\n",
       "43      1.0         0.0        0.0\n",
       "141     0.0         0.0        1.0\n",
       "68      0.0         1.0        0.0\n",
       "143     0.0         0.0        1.0\n",
       "\n",
       "[120 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        species\n",
       "122   virginica\n",
       "107   virginica\n",
       "63   versicolor\n",
       "103   virginica\n",
       "149   virginica\n",
       "..          ...\n",
       "100   virginica\n",
       "43       setosa\n",
       "141   virginica\n",
       "68   versicolor\n",
       "143   virginica\n",
       "\n",
       "[120 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# entrez ci-dessous votre code python\n",
    "data_train = dfi.sample(frac=0.8, axis='index') # on sélectionne au hasard 80% de l'échantillon\n",
    "data_test  = dfi.drop(data_train.index) # on sélectionne le reste\n",
    "\n",
    "x_train = data_train[['sepal_length','sepal_width','petal_length','petal_width']]\n",
    "y_train = data_train[['setosa','versicolor','virginica']]\n",
    "y_train_species = data_train[['species']] #sera utile à la fin pour comparer la prédiction et l'espèce réelle\n",
    "\n",
    "x_test  = data_test[['sepal_length','sepal_width','petal_length','petal_width']]\n",
    "y_test  = data_test[['setosa','versicolor','virginica']]\n",
    "y_test_species = data_test[['species']] #sera utile à la fin pour comparer la prédiction et l'espèce réelle\n",
    "\n",
    "print('x_train : ',x_train.shape)\n",
    "display(x_train)\n",
    "print('y_train : ',y_train.shape,'y_train_species : ',y_train_species.shape)\n",
    "display(y_train, y_train_species)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94b4f9b-46d6-4988-a3f3-ab75734b6ffa",
   "metadata": {},
   "source": [
    "##### **3.** Adaptation des données à la régression logistique par le réseau de neurones\n",
    "\n",
    "On a indiqué dans le cours que toute donnée soumise à l'algorithme (c'est-à-dire toute donnée d'*entrée*) doit au préalable être standardisée à l'aide de la commande `scaler.transform()` du module `scikit learn`.\n",
    "\n",
    "- Appliquer la procédure de façon appropriée\n",
    "- Afficher les données d'apprentissage après standardisation\n",
    "- Faire de même pour les données de test si vous leur avez appliqué la standardisation \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "70779f6b-4820-427f-a2ce-96ac775809a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_8aace\">\n",
       "  <caption>Training set après normalisation (avec scikit-learn):</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_8aace_level0_col0\" class=\"col_heading level0 col0\" >sepal_length</th>\n",
       "      <th id=\"T_8aace_level0_col1\" class=\"col_heading level0 col1\" >sepal_width</th>\n",
       "      <th id=\"T_8aace_level0_col2\" class=\"col_heading level0 col2\" >petal_length</th>\n",
       "      <th id=\"T_8aace_level0_col3\" class=\"col_heading level0 col3\" >petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_8aace_level0_row0\" class=\"row_heading level0 row0\" >count</th>\n",
       "      <td id=\"T_8aace_row0_col0\" class=\"data row0 col0\" >120.00</td>\n",
       "      <td id=\"T_8aace_row0_col1\" class=\"data row0 col1\" >120.00</td>\n",
       "      <td id=\"T_8aace_row0_col2\" class=\"data row0 col2\" >120.00</td>\n",
       "      <td id=\"T_8aace_row0_col3\" class=\"data row0 col3\" >120.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8aace_level0_row1\" class=\"row_heading level0 row1\" >mean</th>\n",
       "      <td id=\"T_8aace_row1_col0\" class=\"data row1 col0\" >-0.00</td>\n",
       "      <td id=\"T_8aace_row1_col1\" class=\"data row1 col1\" >0.00</td>\n",
       "      <td id=\"T_8aace_row1_col2\" class=\"data row1 col2\" >-0.00</td>\n",
       "      <td id=\"T_8aace_row1_col3\" class=\"data row1 col3\" >0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8aace_level0_row2\" class=\"row_heading level0 row2\" >std</th>\n",
       "      <td id=\"T_8aace_row2_col0\" class=\"data row2 col0\" >1.00</td>\n",
       "      <td id=\"T_8aace_row2_col1\" class=\"data row2 col1\" >1.00</td>\n",
       "      <td id=\"T_8aace_row2_col2\" class=\"data row2 col2\" >1.00</td>\n",
       "      <td id=\"T_8aace_row2_col3\" class=\"data row2 col3\" >1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8aace_level0_row3\" class=\"row_heading level0 row3\" >min</th>\n",
       "      <td id=\"T_8aace_row3_col0\" class=\"data row3 col0\" >-1.85</td>\n",
       "      <td id=\"T_8aace_row3_col1\" class=\"data row3 col1\" >-2.41</td>\n",
       "      <td id=\"T_8aace_row3_col2\" class=\"data row3 col2\" >-1.64</td>\n",
       "      <td id=\"T_8aace_row3_col3\" class=\"data row3 col3\" >-1.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8aace_level0_row4\" class=\"row_heading level0 row4\" >25%</th>\n",
       "      <td id=\"T_8aace_row4_col0\" class=\"data row4 col0\" >-0.90</td>\n",
       "      <td id=\"T_8aace_row4_col1\" class=\"data row4 col1\" >-0.53</td>\n",
       "      <td id=\"T_8aace_row4_col2\" class=\"data row4 col2\" >-1.30</td>\n",
       "      <td id=\"T_8aace_row4_col3\" class=\"data row4 col3\" >-1.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8aace_level0_row5\" class=\"row_heading level0 row5\" >50%</th>\n",
       "      <td id=\"T_8aace_row5_col0\" class=\"data row5 col0\" >-0.06</td>\n",
       "      <td id=\"T_8aace_row5_col1\" class=\"data row5 col1\" >-0.05</td>\n",
       "      <td id=\"T_8aace_row5_col2\" class=\"data row5 col2\" >0.37</td>\n",
       "      <td id=\"T_8aace_row5_col3\" class=\"data row5 col3\" >0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8aace_level0_row6\" class=\"row_heading level0 row6\" >75%</th>\n",
       "      <td id=\"T_8aace_row6_col0\" class=\"data row6 col0\" >0.65</td>\n",
       "      <td id=\"T_8aace_row6_col1\" class=\"data row6 col1\" >0.47</td>\n",
       "      <td id=\"T_8aace_row6_col2\" class=\"data row6 col2\" >0.73</td>\n",
       "      <td id=\"T_8aace_row6_col3\" class=\"data row6 col3\" >0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8aace_level0_row7\" class=\"row_heading level0 row7\" >max</th>\n",
       "      <td id=\"T_8aace_row7_col0\" class=\"data row7 col0\" >2.45</td>\n",
       "      <td id=\"T_8aace_row7_col1\" class=\"data row7 col1\" >3.24</td>\n",
       "      <td id=\"T_8aace_row7_col2\" class=\"data row7 col2\" >1.64</td>\n",
       "      <td id=\"T_8aace_row7_col3\" class=\"data row7 col3\" >1.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fce89cca530>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_4644c\">\n",
       "  <caption>Test set after après normalisation (avec scikit-learn):</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_4644c_level0_col0\" class=\"col_heading level0 col0\" >sepal_length</th>\n",
       "      <th id=\"T_4644c_level0_col1\" class=\"col_heading level0 col1\" >sepal_width</th>\n",
       "      <th id=\"T_4644c_level0_col2\" class=\"col_heading level0 col2\" >petal_length</th>\n",
       "      <th id=\"T_4644c_level0_col3\" class=\"col_heading level0 col3\" >petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_4644c_level0_row0\" class=\"row_heading level0 row0\" >count</th>\n",
       "      <td id=\"T_4644c_row0_col0\" class=\"data row0 col0\" >30.00</td>\n",
       "      <td id=\"T_4644c_row0_col1\" class=\"data row0 col1\" >30.00</td>\n",
       "      <td id=\"T_4644c_row0_col2\" class=\"data row0 col2\" >30.00</td>\n",
       "      <td id=\"T_4644c_row0_col3\" class=\"data row0 col3\" >30.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4644c_level0_row1\" class=\"row_heading level0 row1\" >mean</th>\n",
       "      <td id=\"T_4644c_row1_col0\" class=\"data row1 col0\" >-0.05</td>\n",
       "      <td id=\"T_4644c_row1_col1\" class=\"data row1 col1\" >0.36</td>\n",
       "      <td id=\"T_4644c_row1_col2\" class=\"data row1 col2\" >-0.28</td>\n",
       "      <td id=\"T_4644c_row1_col3\" class=\"data row1 col3\" >-0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4644c_level0_row2\" class=\"row_heading level0 row2\" >std</th>\n",
       "      <td id=\"T_4644c_row2_col0\" class=\"data row2 col0\" >0.94</td>\n",
       "      <td id=\"T_4644c_row2_col1\" class=\"data row2 col1\" >1.05</td>\n",
       "      <td id=\"T_4644c_row2_col2\" class=\"data row2 col2\" >1.04</td>\n",
       "      <td id=\"T_4644c_row2_col3\" class=\"data row2 col3\" >0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4644c_level0_row3\" class=\"row_heading level0 row3\" >min</th>\n",
       "      <td id=\"T_4644c_row3_col0\" class=\"data row3 col0\" >-1.49</td>\n",
       "      <td id=\"T_4644c_row3_col1\" class=\"data row3 col1\" >-1.47</td>\n",
       "      <td id=\"T_4644c_row3_col2\" class=\"data row3 col2\" >-1.53</td>\n",
       "      <td id=\"T_4644c_row3_col3\" class=\"data row3 col3\" >-1.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4644c_level0_row4\" class=\"row_heading level0 row4\" >25%</th>\n",
       "      <td id=\"T_4644c_row4_col0\" class=\"data row4 col0\" >-0.78</td>\n",
       "      <td id=\"T_4644c_row4_col1\" class=\"data row4 col1\" >-0.47</td>\n",
       "      <td id=\"T_4644c_row4_col2\" class=\"data row4 col2\" >-1.36</td>\n",
       "      <td id=\"T_4644c_row4_col3\" class=\"data row4 col3\" >-1.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4644c_level0_row5\" class=\"row_heading level0 row5\" >50%</th>\n",
       "      <td id=\"T_4644c_row5_col0\" class=\"data row5 col0\" >-0.36</td>\n",
       "      <td id=\"T_4644c_row5_col1\" class=\"data row5 col1\" >0.42</td>\n",
       "      <td id=\"T_4644c_row5_col2\" class=\"data row5 col2\" >0.02</td>\n",
       "      <td id=\"T_4644c_row5_col3\" class=\"data row5 col3\" >-0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4644c_level0_row6\" class=\"row_heading level0 row6\" >75%</th>\n",
       "      <td id=\"T_4644c_row6_col0\" class=\"data row6 col0\" >0.48</td>\n",
       "      <td id=\"T_4644c_row6_col1\" class=\"data row6 col1\" >1.12</td>\n",
       "      <td id=\"T_4644c_row6_col2\" class=\"data row6 col2\" >0.49</td>\n",
       "      <td id=\"T_4644c_row6_col3\" class=\"data row6 col3\" >0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4644c_level0_row7\" class=\"row_heading level0 row7\" >max</th>\n",
       "      <td id=\"T_4644c_row7_col0\" class=\"data row7 col0\" >2.21</td>\n",
       "      <td id=\"T_4644c_row7_col1\" class=\"data row7 col1\" >2.06</td>\n",
       "      <td id=\"T_4644c_row7_col2\" class=\"data row7 col2\" >1.75</td>\n",
       "      <td id=\"T_4644c_row7_col3\" class=\"data row7 col3\" >1.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fce89f29990>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# entrez ci-dessous votre code python\n",
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(x_train.values)\n",
    "x_trainS = scaler.transform(x_train.values) #returns a numpy array\n",
    "x_testS = scaler.transform(x_test.values) #returns a numpy array\n",
    "x_trainD = pd.DataFrame(x_trainS, columns=x_train.columns, index=x_train.index)\n",
    "x_testD = pd.DataFrame(x_testS, columns=x_test.columns, index=x_test.index)\n",
    "display(x_trainD.describe().style.format(\"{0:.2f}\").set_caption(\"Training set après normalisation (avec scikit-learn):\"))\n",
    "display(x_testD.describe().style.format(\"{0:.2f}\").set_caption(\"Test set after après normalisation (avec scikit-learn):\"))\n",
    "x_train = x_trainS\n",
    "x_test = x_testS\n",
    "del x_trainD, x_testD, x_trainS, x_testS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4048710b-2eaf-4e50-a45e-359c84a939ca",
   "metadata": {},
   "source": [
    "#### **Exercice 2.** Définition et apprentissage du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b4958f-6063-4497-bcd0-95b54b0ace64",
   "metadata": {},
   "source": [
    "##### **1.** Définition du modèle\n",
    "\n",
    "Définir un réseau de neurones par l'implémentation d'une fonction `get_model(NE)` adaptée, où `NE` est le nombre de neurones de la couche d'entrée, passé en paramètre.\n",
    "\n",
    "On propose l'architecture suivante :\n",
    "- une couche de neurones d'entrée\n",
    "- une couche cachée de 7 neurones, activés par la fonction `relu`\n",
    "- une deuxième couche cachée, de 5 neurones, eux aussi activés par la fonction `relu`\n",
    "- une couche de sortie, avec le nombre de neurones approprié. On vous laisse le choix d'utiliser ou pas la fonction d'activation `softmax `\n",
    "\n",
    "L'apprentissage se fera à l'aide de l'optimiseur `adam`, qui cherchera à minimiser la fonction `categorical_crossentropy`. On utilisera le mot-clef `accuracy` pour la métrique. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "776ea4a4-a5f4-4898-886d-cec103569b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entrez ci-dessous votre code python\n",
    "def get_model(NE): #NE = nombre de neurones d'entrée\n",
    "    \n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Input(NE, name='iLayer'))\n",
    "    model.add(keras.layers.Dense(7, activation='relu', name='hLayer1'))\n",
    "    model.add(keras.layers.Dense(5, activation='relu', name='hLayer2'))\n",
    "    model.add(keras.layers.Dense(3, activation='softmax', name='oLayer'))\n",
    "    \n",
    "    model.compile(optimizer = 'adam',\n",
    "                  loss      = 'categorical_crossentropy',\n",
    "                  metrics   = ['accuracy'] )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32938fc-ef05-46d6-9f26-80a727d0bc8f",
   "metadata": {},
   "source": [
    "##### **2.** Apprentissage supervisé du réseau de neurones\n",
    "\n",
    "C'est maitenant qu'on lance l'apprentissage. On rappelle que :\n",
    "- on définit d'abord le modèle `ANNmodel=define_model( (4,)) `\n",
    "- on lance son optimisation `ANNmodel.fit`\n",
    "- l'algorithme (l'IA) optimal ainsi que les algorithmes intermédiaires vont être sauvegardés en tant que `ANNhistory`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "877b00e0-83b3-4540-ad09-ffa631fde346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train. Structure (shape) : (120, 4)\n",
      "x_test. Structure (shape) : (30, 4)\n",
      "y_train. Structure (shape) : (120, 3)\n",
      "y_test. Structure (shape) : (30, 3)\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " hLayer1 (Dense)             (None, 7)                 35        \n",
      "                                                                 \n",
      " hLayer2 (Dense)             (None, 5)                 40        \n",
      "                                                                 \n",
      " oLayer (Dense)              (None, 3)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 93\n",
      "Trainable params: 93\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/700\n",
      "24/24 [==============================] - 1s 10ms/step - loss: 1.0972 - accuracy: 0.1500 - val_loss: 1.0869 - val_accuracy: 0.2333\n",
      "Epoch 2/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1.0547 - accuracy: 0.2583 - val_loss: 1.0518 - val_accuracy: 0.2333\n",
      "Epoch 3/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1.0113 - accuracy: 0.4583 - val_loss: 1.0185 - val_accuracy: 0.4333\n",
      "Epoch 4/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.9630 - accuracy: 0.6000 - val_loss: 0.9839 - val_accuracy: 0.4667\n",
      "Epoch 5/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.9135 - accuracy: 0.6333 - val_loss: 0.9507 - val_accuracy: 0.5667\n",
      "Epoch 6/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.8697 - accuracy: 0.6500 - val_loss: 0.9188 - val_accuracy: 0.6333\n",
      "Epoch 7/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.8260 - accuracy: 0.6667 - val_loss: 0.8852 - val_accuracy: 0.6333\n",
      "Epoch 8/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.7863 - accuracy: 0.6750 - val_loss: 0.8509 - val_accuracy: 0.6667\n",
      "Epoch 9/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.7499 - accuracy: 0.6833 - val_loss: 0.8121 - val_accuracy: 0.6667\n",
      "Epoch 10/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.7135 - accuracy: 0.6833 - val_loss: 0.7709 - val_accuracy: 0.6667\n",
      "Epoch 11/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.6746 - accuracy: 0.6917 - val_loss: 0.7210 - val_accuracy: 0.6667\n",
      "Epoch 12/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.6320 - accuracy: 0.7000 - val_loss: 0.6671 - val_accuracy: 0.7000\n",
      "Epoch 13/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.5901 - accuracy: 0.7167 - val_loss: 0.6130 - val_accuracy: 0.7000\n",
      "Epoch 14/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.5471 - accuracy: 0.7250 - val_loss: 0.5640 - val_accuracy: 0.7000\n",
      "Epoch 15/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.5087 - accuracy: 0.7417 - val_loss: 0.5188 - val_accuracy: 0.7333\n",
      "Epoch 16/700\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.4767 - accuracy: 0.7583 - val_loss: 0.4833 - val_accuracy: 0.7667\n",
      "Epoch 17/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.4508 - accuracy: 0.7833 - val_loss: 0.4507 - val_accuracy: 0.7667\n",
      "Epoch 18/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.4281 - accuracy: 0.7917 - val_loss: 0.4303 - val_accuracy: 0.7667\n",
      "Epoch 19/700\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.4101 - accuracy: 0.8167 - val_loss: 0.4129 - val_accuracy: 0.7667\n",
      "Epoch 20/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.3939 - accuracy: 0.8250 - val_loss: 0.3948 - val_accuracy: 0.8000\n",
      "Epoch 21/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.3801 - accuracy: 0.8333 - val_loss: 0.3828 - val_accuracy: 0.8000\n",
      "Epoch 22/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.3675 - accuracy: 0.8417 - val_loss: 0.3704 - val_accuracy: 0.8000\n",
      "Epoch 23/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.3559 - accuracy: 0.8417 - val_loss: 0.3598 - val_accuracy: 0.8000\n",
      "Epoch 24/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.3452 - accuracy: 0.8667 - val_loss: 0.3514 - val_accuracy: 0.8000\n",
      "Epoch 25/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.3352 - accuracy: 0.8833 - val_loss: 0.3412 - val_accuracy: 0.8000\n",
      "Epoch 26/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.3247 - accuracy: 0.8833 - val_loss: 0.3322 - val_accuracy: 0.8000\n",
      "Epoch 27/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.3159 - accuracy: 0.8750 - val_loss: 0.3266 - val_accuracy: 0.8000\n",
      "Epoch 28/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.3051 - accuracy: 0.8917 - val_loss: 0.3192 - val_accuracy: 0.8000\n",
      "Epoch 29/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.2957 - accuracy: 0.8833 - val_loss: 0.3065 - val_accuracy: 0.8333\n",
      "Epoch 30/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.2849 - accuracy: 0.9083 - val_loss: 0.3041 - val_accuracy: 0.8333\n",
      "Epoch 31/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.2746 - accuracy: 0.9083 - val_loss: 0.2937 - val_accuracy: 0.8333\n",
      "Epoch 32/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.2644 - accuracy: 0.9083 - val_loss: 0.2817 - val_accuracy: 0.8667\n",
      "Epoch 33/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.2550 - accuracy: 0.9167 - val_loss: 0.2722 - val_accuracy: 0.8667\n",
      "Epoch 34/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.2464 - accuracy: 0.9250 - val_loss: 0.2620 - val_accuracy: 0.9000\n",
      "Epoch 35/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.2366 - accuracy: 0.9417 - val_loss: 0.2571 - val_accuracy: 0.8667\n",
      "Epoch 36/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.2296 - accuracy: 0.9333 - val_loss: 0.2481 - val_accuracy: 0.9000\n",
      "Epoch 37/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.2204 - accuracy: 0.9583 - val_loss: 0.2396 - val_accuracy: 0.9000\n",
      "Epoch 38/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.2144 - accuracy: 0.9583 - val_loss: 0.2245 - val_accuracy: 0.9000\n",
      "Epoch 39/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.2036 - accuracy: 0.9583 - val_loss: 0.2202 - val_accuracy: 0.9000\n",
      "Epoch 40/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.1968 - accuracy: 0.9583 - val_loss: 0.2187 - val_accuracy: 0.9000\n",
      "Epoch 41/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.1893 - accuracy: 0.9667 - val_loss: 0.2037 - val_accuracy: 0.9333\n",
      "Epoch 42/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.1833 - accuracy: 0.9667 - val_loss: 0.1982 - val_accuracy: 0.9333\n",
      "Epoch 43/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.1754 - accuracy: 0.9667 - val_loss: 0.1880 - val_accuracy: 0.9333\n",
      "Epoch 44/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.1692 - accuracy: 0.9750 - val_loss: 0.1828 - val_accuracy: 0.9333\n",
      "Epoch 45/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.1624 - accuracy: 0.9750 - val_loss: 0.1789 - val_accuracy: 0.9333\n",
      "Epoch 46/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.1581 - accuracy: 0.9750 - val_loss: 0.1663 - val_accuracy: 0.9667\n",
      "Epoch 47/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.1499 - accuracy: 0.9750 - val_loss: 0.1669 - val_accuracy: 0.9667\n",
      "Epoch 48/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.1457 - accuracy: 0.9750 - val_loss: 0.1581 - val_accuracy: 0.9667\n",
      "Epoch 49/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.1398 - accuracy: 0.9750 - val_loss: 0.1522 - val_accuracy: 0.9667\n",
      "Epoch 50/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.1343 - accuracy: 0.9750 - val_loss: 0.1444 - val_accuracy: 0.9667\n",
      "Epoch 51/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.1297 - accuracy: 0.9750 - val_loss: 0.1409 - val_accuracy: 0.9667\n",
      "Epoch 52/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.1255 - accuracy: 0.9750 - val_loss: 0.1343 - val_accuracy: 0.9667\n",
      "Epoch 53/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.1215 - accuracy: 0.9750 - val_loss: 0.1285 - val_accuracy: 0.9667\n",
      "Epoch 54/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.1176 - accuracy: 0.9750 - val_loss: 0.1228 - val_accuracy: 0.9667\n",
      "Epoch 55/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.1141 - accuracy: 0.9750 - val_loss: 0.1247 - val_accuracy: 0.9667\n",
      "Epoch 56/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.1117 - accuracy: 0.9750 - val_loss: 0.1142 - val_accuracy: 0.9667\n",
      "Epoch 57/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.1069 - accuracy: 0.9750 - val_loss: 0.1138 - val_accuracy: 0.9667\n",
      "Epoch 58/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.1052 - accuracy: 0.9750 - val_loss: 0.1108 - val_accuracy: 0.9667\n",
      "Epoch 59/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.1024 - accuracy: 0.9750 - val_loss: 0.1009 - val_accuracy: 0.9667\n",
      "Epoch 60/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.1017 - accuracy: 0.9750 - val_loss: 0.1072 - val_accuracy: 0.9667\n",
      "Epoch 61/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0957 - accuracy: 0.9750 - val_loss: 0.0985 - val_accuracy: 0.9667\n",
      "Epoch 62/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0936 - accuracy: 0.9750 - val_loss: 0.0952 - val_accuracy: 0.9667\n",
      "Epoch 63/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0916 - accuracy: 0.9750 - val_loss: 0.0930 - val_accuracy: 0.9667\n",
      "Epoch 64/700\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.0895 - accuracy: 0.9750 - val_loss: 0.0906 - val_accuracy: 0.9667\n",
      "Epoch 65/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0877 - accuracy: 0.9750 - val_loss: 0.0921 - val_accuracy: 0.9667\n",
      "Epoch 66/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0862 - accuracy: 0.9833 - val_loss: 0.0863 - val_accuracy: 0.9667\n",
      "Epoch 67/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0840 - accuracy: 0.9750 - val_loss: 0.0825 - val_accuracy: 0.9667\n",
      "Epoch 68/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0825 - accuracy: 0.9750 - val_loss: 0.0839 - val_accuracy: 0.9667\n",
      "Epoch 69/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0812 - accuracy: 0.9750 - val_loss: 0.0844 - val_accuracy: 0.9667\n",
      "Epoch 70/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0787 - accuracy: 0.9833 - val_loss: 0.0802 - val_accuracy: 0.9667\n",
      "Epoch 71/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0777 - accuracy: 0.9833 - val_loss: 0.0772 - val_accuracy: 0.9667\n",
      "Epoch 72/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0765 - accuracy: 0.9833 - val_loss: 0.0775 - val_accuracy: 0.9667\n",
      "Epoch 73/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0751 - accuracy: 0.9917 - val_loss: 0.0740 - val_accuracy: 0.9667\n",
      "Epoch 74/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0739 - accuracy: 0.9833 - val_loss: 0.0746 - val_accuracy: 0.9667\n",
      "Epoch 75/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0727 - accuracy: 0.9917 - val_loss: 0.0724 - val_accuracy: 0.9667\n",
      "Epoch 76/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0722 - accuracy: 0.9917 - val_loss: 0.0725 - val_accuracy: 0.9667\n",
      "Epoch 77/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0706 - accuracy: 0.9917 - val_loss: 0.0714 - val_accuracy: 0.9667\n",
      "Epoch 78/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0700 - accuracy: 0.9917 - val_loss: 0.0692 - val_accuracy: 0.9667\n",
      "Epoch 79/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0695 - accuracy: 0.9833 - val_loss: 0.0696 - val_accuracy: 0.9667\n",
      "Epoch 80/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0681 - accuracy: 0.9917 - val_loss: 0.0710 - val_accuracy: 0.9667\n",
      "Epoch 81/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0676 - accuracy: 0.9917 - val_loss: 0.0646 - val_accuracy: 0.9667\n",
      "Epoch 82/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0662 - accuracy: 0.9917 - val_loss: 0.0664 - val_accuracy: 0.9667\n",
      "Epoch 83/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0649 - accuracy: 0.9917 - val_loss: 0.0675 - val_accuracy: 0.9667\n",
      "Epoch 84/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0655 - accuracy: 0.9917 - val_loss: 0.0698 - val_accuracy: 0.9667\n",
      "Epoch 85/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0641 - accuracy: 0.9917 - val_loss: 0.0676 - val_accuracy: 0.9667\n",
      "Epoch 86/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0657 - accuracy: 0.9833 - val_loss: 0.0628 - val_accuracy: 0.9667\n",
      "Epoch 87/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0631 - accuracy: 0.9917 - val_loss: 0.0633 - val_accuracy: 0.9667\n",
      "Epoch 88/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0629 - accuracy: 0.9833 - val_loss: 0.0614 - val_accuracy: 0.9667\n",
      "Epoch 89/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0644 - accuracy: 0.9917 - val_loss: 0.0691 - val_accuracy: 0.9667\n",
      "Epoch 90/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0613 - accuracy: 0.9917 - val_loss: 0.0602 - val_accuracy: 0.9667\n",
      "Epoch 91/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0620 - accuracy: 0.9917 - val_loss: 0.0655 - val_accuracy: 0.9667\n",
      "Epoch 92/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0593 - accuracy: 0.9917 - val_loss: 0.0618 - val_accuracy: 0.9667\n",
      "Epoch 93/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0592 - accuracy: 0.9917 - val_loss: 0.0578 - val_accuracy: 0.9667\n",
      "Epoch 94/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0587 - accuracy: 0.9917 - val_loss: 0.0613 - val_accuracy: 0.9667\n",
      "Epoch 95/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0588 - accuracy: 0.9917 - val_loss: 0.0587 - val_accuracy: 0.9667\n",
      "Epoch 96/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0581 - accuracy: 0.9917 - val_loss: 0.0617 - val_accuracy: 0.9667\n",
      "Epoch 97/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0582 - accuracy: 0.9917 - val_loss: 0.0605 - val_accuracy: 0.9667\n",
      "Epoch 98/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0575 - accuracy: 0.9833 - val_loss: 0.0560 - val_accuracy: 0.9667\n",
      "Epoch 99/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0571 - accuracy: 0.9917 - val_loss: 0.0581 - val_accuracy: 0.9667\n",
      "Epoch 100/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0562 - accuracy: 0.9917 - val_loss: 0.0569 - val_accuracy: 0.9667\n",
      "Epoch 101/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0569 - accuracy: 0.9917 - val_loss: 0.0569 - val_accuracy: 0.9667\n",
      "Epoch 102/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0555 - accuracy: 0.9917 - val_loss: 0.0588 - val_accuracy: 0.9667\n",
      "Epoch 103/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0556 - accuracy: 0.9917 - val_loss: 0.0583 - val_accuracy: 0.9667\n",
      "Epoch 104/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0545 - accuracy: 0.9917 - val_loss: 0.0552 - val_accuracy: 0.9667\n",
      "Epoch 105/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0546 - accuracy: 0.9917 - val_loss: 0.0556 - val_accuracy: 0.9667\n",
      "Epoch 106/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0542 - accuracy: 0.9917 - val_loss: 0.0561 - val_accuracy: 0.9667\n",
      "Epoch 107/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0556 - accuracy: 0.9833 - val_loss: 0.0534 - val_accuracy: 0.9667\n",
      "Epoch 108/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0525 - accuracy: 0.9917 - val_loss: 0.0571 - val_accuracy: 0.9667\n",
      "Epoch 109/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0537 - accuracy: 0.9917 - val_loss: 0.0606 - val_accuracy: 0.9667\n",
      "Epoch 110/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0525 - accuracy: 0.9917 - val_loss: 0.0575 - val_accuracy: 0.9667\n",
      "Epoch 111/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0517 - accuracy: 0.9917 - val_loss: 0.0534 - val_accuracy: 0.9667\n",
      "Epoch 112/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0530 - accuracy: 0.9917 - val_loss: 0.0521 - val_accuracy: 0.9667\n",
      "Epoch 113/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0540 - accuracy: 0.9750 - val_loss: 0.0549 - val_accuracy: 0.9667\n",
      "Epoch 114/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0538 - accuracy: 0.9833 - val_loss: 0.0541 - val_accuracy: 0.9667\n",
      "Epoch 115/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0526 - accuracy: 0.9917 - val_loss: 0.0567 - val_accuracy: 0.9667\n",
      "Epoch 116/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0517 - accuracy: 0.9917 - val_loss: 0.0545 - val_accuracy: 0.9667\n",
      "Epoch 117/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0526 - accuracy: 0.9917 - val_loss: 0.0524 - val_accuracy: 0.9667\n",
      "Epoch 118/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0509 - accuracy: 0.9917 - val_loss: 0.0530 - val_accuracy: 0.9667\n",
      "Epoch 119/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0509 - accuracy: 0.9917 - val_loss: 0.0518 - val_accuracy: 0.9667\n",
      "Epoch 120/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0523 - accuracy: 0.9833 - val_loss: 0.0509 - val_accuracy: 0.9667\n",
      "Epoch 121/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0499 - accuracy: 0.9917 - val_loss: 0.0552 - val_accuracy: 0.9667\n",
      "Epoch 122/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0521 - accuracy: 0.9917 - val_loss: 0.0589 - val_accuracy: 0.9667\n",
      "Epoch 123/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0495 - accuracy: 0.9917 - val_loss: 0.0506 - val_accuracy: 0.9667\n",
      "Epoch 124/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0498 - accuracy: 0.9917 - val_loss: 0.0507 - val_accuracy: 0.9667\n",
      "Epoch 125/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0497 - accuracy: 0.9917 - val_loss: 0.0550 - val_accuracy: 0.9667\n",
      "Epoch 126/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0487 - accuracy: 0.9917 - val_loss: 0.0529 - val_accuracy: 0.9667\n",
      "Epoch 127/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0491 - accuracy: 0.9917 - val_loss: 0.0518 - val_accuracy: 0.9667\n",
      "Epoch 128/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0493 - accuracy: 0.9917 - val_loss: 0.0515 - val_accuracy: 0.9667\n",
      "Epoch 129/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0482 - accuracy: 0.9917 - val_loss: 0.0531 - val_accuracy: 0.9667\n",
      "Epoch 130/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0485 - accuracy: 0.9917 - val_loss: 0.0535 - val_accuracy: 0.9667\n",
      "Epoch 131/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0486 - accuracy: 0.9917 - val_loss: 0.0537 - val_accuracy: 0.9667\n",
      "Epoch 132/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0516 - accuracy: 0.9917 - val_loss: 0.0549 - val_accuracy: 0.9667\n",
      "Epoch 133/700\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0489 - accuracy: 0.9917 - val_loss: 0.0530 - val_accuracy: 0.9667\n",
      "Epoch 133: early stopping\n",
      "\n",
      "Duration :  00:00:11 800ms\n"
     ]
    }
   ],
   "source": [
    "# exécutez cette cellule, sans la modifier\n",
    "vID.chrono_start()\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
    "print(f\"x_train. Structure (shape) : {x_train.shape}\")\n",
    "print(f\"x_test. Structure (shape) : {x_test.shape}\")\n",
    "print(f\"y_train. Structure (shape) : {y_train.shape}\")\n",
    "print(f\"y_test. Structure (shape) : {y_test.shape}\")\n",
    "ANNmodel=get_model( (4,)) # 4 neurones d'entrée\n",
    "ANNmodel.summary()\n",
    "vID.chrono_start()\n",
    "ANNhistory = ANNmodel.fit(x_train,\n",
    "                    y_train,\n",
    "                    epochs          = 700,\n",
    "                    batch_size      = 5,\n",
    "                    verbose         = 1,\n",
    "                    validation_data = (x_test, y_test),\n",
    "                    callbacks=[es])\n",
    "vID.chrono_show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d024f113-ac6b-4f13-a3cc-10bd4234a98b",
   "metadata": {},
   "source": [
    "#### **Exercice 3.** Évaluation du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f927a6-ce28-443a-b4f9-0c47140e51ef",
   "metadata": {},
   "source": [
    "##### **1.** Évaluation globale de la précision du modèle\n",
    "\n",
    "Utiliser la fonction `evaluate` de `Keras` afin de renvoyer les valeurs des erreurs \"loss\" et \"accuracy\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fe7d2f5f-14a3-4484-9cc6-69a080e0212b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mx_train / loss      : 0.0471\u001b[0m\n",
      "\u001b[92mx_train/ accurracy  : 0.9917\u001b[0m\n",
      "\n",
      "\u001b[94mx_test / loss      : 0.0530\u001b[0m\n",
      "\u001b[94mx_test/ accurracy  : 0.9667\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# entrez ci-dessous votre code python\n",
    "evalANN_on_Train = ANNmodel.evaluate(x_train, y_train, verbose=0)\n",
    "print(f\"{color.GREEN}x_train / loss      : {evalANN_on_Train[0]:5.4f}{color.OFF}\")\n",
    "print(f\"{color.GREEN}x_train/ accurracy  : {evalANN_on_Train[1]:5.4f}{color.OFF}\")\n",
    "print()\n",
    "evalANN_on_Test = ANNmodel.evaluate(x_test, y_test, verbose=0)\n",
    "print(f\"{color.BLUE}x_test / loss      : {evalANN_on_Test[0]:5.4f}{color.OFF}\")\n",
    "print(f\"{color.BLUE}x_test/ accurracy  : {evalANN_on_Test[1]:5.4f}{color.OFF}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5149669f-0ee6-4f8f-9f40-1cb91e4929ad",
   "metadata": {},
   "source": [
    "##### **2.** Comportement du modèle vis-à-vis de chaque espèce d'iris\n",
    "\n",
    "- Afficher les probailités pour chacun des échantillons du jeu d'apprentissage (`xtrain` et `y_train`).\n",
    "- Les convertir en espèce d'iris grâce à `argmax` et à la liste `dfi['species'].unique()` qu'on sauvera dans une variable nomée `usp`. On peut ainsi directement comparer avec les espèces réellement observées\n",
    "- comptabiliser enfin les erreurs commises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "35c740a5-53e5-4776-8cea-b53af7589366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[92mCatégories uniques d'iris :\u001b[0m ['setosa' 'versicolor' 'virginica']\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "\u001b[1m\u001b[94mTest Set\u001b[0m. Comparaison entre espèce prédite et espèce observée\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>setosa</th>\n",
       "      <th>versicolor</th>\n",
       "      <th>virginica</th>\n",
       "      <th>Espèce prédite</th>\n",
       "      <th>Espèce observée</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.05</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.99</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.95</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.92</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.02</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.14</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.57</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.36</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.20</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.92</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.12</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.98</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.99</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.82</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.87</td>\n",
       "      <td>virginica</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.98</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.83</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.99</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.98</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.05</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.02</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.59</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.00</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.98</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.86</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.95</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.99</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.02</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.13</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     setosa  versicolor  virginica Espèce prédite Espèce observée\n",
       "122    0.00        0.00       1.00      virginica       virginica\n",
       "107    0.00        0.00       1.00      virginica       virginica\n",
       "63     0.00        0.95       0.05     versicolor      versicolor\n",
       "103    0.00        0.01       0.99      virginica       virginica\n",
       "149    0.00        0.05       0.95      virginica       virginica\n",
       "140    0.00        0.00       1.00      virginica       virginica\n",
       "123    0.00        0.08       0.92      virginica       virginica\n",
       "53     0.00        0.98       0.02     versicolor      versicolor\n",
       "136    0.00        0.00       1.00      virginica       virginica\n",
       "73     0.00        0.99       0.01     versicolor      versicolor\n",
       "130    0.00        0.00       1.00      virginica       virginica\n",
       "128    0.00        0.00       1.00      virginica       virginica\n",
       "52     0.00        0.86       0.14     versicolor      versicolor\n",
       "90     0.00        0.99       0.01     versicolor      versicolor\n",
       "133    0.00        0.43       0.57      virginica       virginica\n",
       "72     0.00        0.64       0.36     versicolor      versicolor\n",
       "95     0.01        0.99       0.00     versicolor      versicolor\n",
       "98     0.01        0.99       0.00     versicolor      versicolor\n",
       "33     1.00        0.00       0.00         setosa          setosa\n",
       "30     1.00        0.00       0.00         setosa          setosa\n",
       "17     1.00        0.00       0.00         setosa          setosa\n",
       "42     1.00        0.00       0.00         setosa          setosa\n",
       "51     0.00        0.99       0.01     versicolor      versicolor\n",
       "19     1.00        0.00       0.00         setosa          setosa\n",
       "70     0.00        0.80       0.20     versicolor      versicolor\n",
       "99     0.00        1.00       0.00     versicolor      versicolor\n",
       "126    0.00        0.08       0.92      virginica       virginica\n",
       "135    0.00        0.00       1.00      virginica       virginica\n",
       "89     0.00        0.99       0.01     versicolor      versicolor\n",
       "54     0.00        0.88       0.12     versicolor      versicolor\n",
       "80     0.00        1.00       0.00     versicolor      versicolor\n",
       "116    0.00        0.02       0.98      virginica       virginica\n",
       "120    0.00        0.00       1.00      virginica       virginica\n",
       "142    0.00        0.00       1.00      virginica       virginica\n",
       "38     1.00        0.00       0.00         setosa          setosa\n",
       "84     0.00        0.99       0.01     versicolor      versicolor\n",
       "102    0.00        0.00       1.00      virginica       virginica\n",
       "88     0.01        0.99       0.00     versicolor      versicolor\n",
       "85     0.01        0.99       0.00     versicolor      versicolor\n",
       "131    0.00        0.01       0.99      virginica       virginica\n",
       "139    0.00        0.00       1.00      virginica       virginica\n",
       "145    0.00        0.00       1.00      virginica       virginica\n",
       "134    0.00        0.18       0.82      virginica       virginica\n",
       "26     1.00        0.00       0.00         setosa          setosa\n",
       "115    0.00        0.00       1.00      virginica       virginica\n",
       "91     0.00        0.99       0.01     versicolor      versicolor\n",
       "83     0.00        0.13       0.87      virginica      versicolor\n",
       "57     0.00        1.00       0.00     versicolor      versicolor\n",
       "87     0.00        0.99       0.01     versicolor      versicolor\n",
       "31     1.00        0.00       0.00         setosa          setosa\n",
       "3      1.00        0.00       0.00         setosa          setosa\n",
       "124    0.00        0.00       1.00      virginica       virginica\n",
       "146    0.00        0.02       0.98      virginica       virginica\n",
       "13     1.00        0.00       0.00         setosa          setosa\n",
       "93     0.00        1.00       0.00     versicolor      versicolor\n",
       "138    0.00        0.17       0.83      virginica       virginica\n",
       "111    0.00        0.01       0.99      virginica       virginica\n",
       "110    0.00        0.02       0.98      virginica       virginica\n",
       "94     0.00        1.00       0.00     versicolor      versicolor\n",
       "76     0.00        0.95       0.05     versicolor      versicolor\n",
       "8      1.00        0.00       0.00         setosa          setosa\n",
       "112    0.00        0.00       1.00      virginica       virginica\n",
       "62     0.00        1.00       0.00     versicolor      versicolor\n",
       "7      1.00        0.00       0.00         setosa          setosa\n",
       "41     0.96        0.04       0.00         setosa          setosa\n",
       "50     0.00        0.98       0.02     versicolor      versicolor\n",
       "9      1.00        0.00       0.00         setosa          setosa\n",
       "121    0.00        0.00       1.00      virginica       virginica\n",
       "12     1.00        0.00       0.00         setosa          setosa\n",
       "119    0.00        0.41       0.59      virginica       virginica\n",
       "64     0.04        0.96       0.00     versicolor      versicolor\n",
       "148    0.00        0.00       1.00      virginica       virginica\n",
       "117    0.00        0.00       1.00      virginica       virginica\n",
       "113    0.00        0.00       1.00      virginica       virginica\n",
       "137    0.00        0.02       0.98      virginica       virginica\n",
       "129    0.00        0.14       0.86      virginica       virginica\n",
       "29     1.00        0.00       0.00         setosa          setosa\n",
       "37     1.00        0.00       0.00         setosa          setosa\n",
       "105    0.00        0.00       1.00      virginica       virginica\n",
       "4      1.00        0.00       0.00         setosa          setosa\n",
       "15     1.00        0.00       0.00         setosa          setosa\n",
       "106    0.00        0.05       0.95      virginica       virginica\n",
       "66     0.00        0.99       0.01     versicolor      versicolor\n",
       "24     1.00        0.00       0.00         setosa          setosa\n",
       "79     0.00        0.99       0.00     versicolor      versicolor\n",
       "34     1.00        0.00       0.00         setosa          setosa\n",
       "14     1.00        0.00       0.00         setosa          setosa\n",
       "114    0.00        0.00       1.00      virginica       virginica\n",
       "96     0.00        0.99       0.00     versicolor      versicolor\n",
       "92     0.00        0.99       0.01     versicolor      versicolor\n",
       "49     1.00        0.00       0.00         setosa          setosa\n",
       "39     1.00        0.00       0.00         setosa          setosa\n",
       "75     0.00        0.99       0.01     versicolor      versicolor\n",
       "67     0.00        0.99       0.00     versicolor      versicolor\n",
       "48     1.00        0.00       0.00         setosa          setosa\n",
       "147    0.00        0.01       0.99      virginica       virginica\n",
       "45     1.00        0.00       0.00         setosa          setosa\n",
       "11     1.00        0.00       0.00         setosa          setosa\n",
       "32     1.00        0.00       0.00         setosa          setosa\n",
       "104    0.00        0.00       1.00      virginica       virginica\n",
       "60     0.00        1.00       0.00     versicolor      versicolor\n",
       "97     0.00        0.99       0.01     versicolor      versicolor\n",
       "55     0.00        0.99       0.01     versicolor      versicolor\n",
       "144    0.00        0.00       1.00      virginica       virginica\n",
       "0      1.00        0.00       0.00         setosa          setosa\n",
       "6      1.00        0.00       0.00         setosa          setosa\n",
       "58     0.00        0.98       0.02     versicolor      versicolor\n",
       "132    0.00        0.00       1.00      virginica       virginica\n",
       "23     1.00        0.00       0.00         setosa          setosa\n",
       "74     0.00        0.99       0.01     versicolor      versicolor\n",
       "40     1.00        0.00       0.00         setosa          setosa\n",
       "22     1.00        0.00       0.00         setosa          setosa\n",
       "25     1.00        0.00       0.00         setosa          setosa\n",
       "1      1.00        0.00       0.00         setosa          setosa\n",
       "18     1.00        0.00       0.00         setosa          setosa\n",
       "100    0.00        0.00       1.00      virginica       virginica\n",
       "43     1.00        0.00       0.00         setosa          setosa\n",
       "141    0.00        0.00       1.00      virginica       virginica\n",
       "68     0.00        0.87       0.13     versicolor      versicolor\n",
       "143    0.00        0.00       1.00      virginica       virginica"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'erreurs : 1\n",
      "\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "\u001b[1m\u001b[91mTest Set\u001b[0m. Comparaison entre espèce prédite et espèce observée.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>setosa</th>\n",
       "      <th>versicolor</th>\n",
       "      <th>virginica</th>\n",
       "      <th>Espèce prédite</th>\n",
       "      <th>Espèce observée</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.72</td>\n",
       "      <td>virginica</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.07</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.06</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.99</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.98</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.91</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     setosa  versicolor  virginica Espèce prédite Espèce observée\n",
       "2      1.00        0.00       0.00         setosa          setosa\n",
       "5      1.00        0.00       0.00         setosa          setosa\n",
       "10     1.00        0.00       0.00         setosa          setosa\n",
       "16     1.00        0.00       0.00         setosa          setosa\n",
       "20     1.00        0.00       0.00         setosa          setosa\n",
       "21     1.00        0.00       0.00         setosa          setosa\n",
       "27     1.00        0.00       0.00         setosa          setosa\n",
       "28     1.00        0.00       0.00         setosa          setosa\n",
       "35     1.00        0.00       0.00         setosa          setosa\n",
       "36     1.00        0.00       0.00         setosa          setosa\n",
       "44     1.00        0.00       0.00         setosa          setosa\n",
       "46     1.00        0.00       0.00         setosa          setosa\n",
       "47     1.00        0.00       0.00         setosa          setosa\n",
       "56     0.00        0.99       0.01     versicolor      versicolor\n",
       "59     0.00        1.00       0.00     versicolor      versicolor\n",
       "61     0.00        0.99       0.01     versicolor      versicolor\n",
       "65     0.00        0.99       0.01     versicolor      versicolor\n",
       "69     0.00        1.00       0.00     versicolor      versicolor\n",
       "71     0.00        0.99       0.01     versicolor      versicolor\n",
       "77     0.00        0.28       0.72      virginica      versicolor\n",
       "78     0.00        0.93       0.07     versicolor      versicolor\n",
       "81     0.00        1.00       0.00     versicolor      versicolor\n",
       "82     0.00        0.99       0.00     versicolor      versicolor\n",
       "86     0.00        0.94       0.06     versicolor      versicolor\n",
       "101    0.00        0.00       1.00      virginica       virginica\n",
       "108    0.00        0.01       0.99      virginica       virginica\n",
       "109    0.00        0.00       1.00      virginica       virginica\n",
       "118    0.00        0.00       1.00      virginica       virginica\n",
       "125    0.00        0.02       0.98      virginica       virginica\n",
       "127    0.00        0.09       0.91      virginica       virginica"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'erreurs : 1\n"
     ]
    }
   ],
   "source": [
    "# entrez ci-dessous votre code python\n",
    "usp = dfi['species'].unique()\n",
    "print(f\"{color.BOLD}{color.GREEN}Catégories uniques d'iris :{color.OFF} {usp}\")\n",
    "# cette correspondance élément 0 <-> setosa ; élément 1 <-> versicolor ; élément 2 <-> virginica\n",
    "# va servir à transformer les probabilités les plus élevées en espèce d'iris\n",
    "\n",
    "y_train_hat=ANNmodel.predict(x_train)\n",
    "ytr_hD = pd.DataFrame(y_train_hat, columns=usp, index=y_train.index)\n",
    "# argmax renvoie l'indice de la valeur maximale selon un axe (0 = ligne / 1 = colonne)\n",
    "# ça va ici nous renvoyer pour chaque ligne le numéro de la colonne qui contient la plus grande valeur de probabilité\n",
    "# on convertit maintenant 0, 1 & 2 en espèce d'iris\n",
    "iris_tr_hat = usp[np.argmax(y_train_hat,axis=1)]\n",
    "# on ajoute cette colonne au dataframe ytr_hD\n",
    "ytr_hD['Espèce prédite'] = pd.DataFrame(iris_tr_hat, index=y_train.index)\n",
    "ytr_hD['Espèce observée'] = pd.DataFrame(y_train_species, index=y_train.index)\n",
    "print(f\"{color.BOLD}{color.BLUE}Test Set{color.OFF}. Comparaison entre espèce prédite et espèce observée\")\n",
    "pd.set_option('display.max_rows', None) #on veut afficher toutes les lignes des DataFrames\n",
    "pd.options.display.float_format = '{:,.2f}'.format #on formatte les probabilités, sinon c'est illisible\n",
    "display(ytr_hD)\n",
    "pd.set_option('display.max_rows', 10) #reset de l'affichage: 5 premières et 5 dernières lignes\n",
    "pd.options.display.float_format = None #reset de l'affichage: format standard \n",
    "diff_Pred_Obs=np.where(ytr_hD['Espèce prédite'] == ytr_hD['Espèce observée'], 0, 1)\n",
    "print(f\"Nombre d'erreurs : {np.sum(diff_Pred_Obs)}\")\n",
    "\n",
    "print()\n",
    "y_test_hat=ANNmodel.predict(x_test)\n",
    "ytt_hD = pd.DataFrame(y_test_hat, columns=usp, index=y_test.index)\n",
    "# argmax renvoie l'indice de la valeur maximale selon un axe (0 = ligne / 1 = colonne)\n",
    "# ça va ici nous renvoyer pour chaque ligne le numéro de la colonne qui contient la plus grande valeur de probabilité\n",
    "# on convertit maintenant 0, 1 & 2 en espèce d'iris\n",
    "iris_tt_hat = usp[np.argmax(y_test_hat,axis=1)]\n",
    "# on ajoute cette colonne au dataframe ytt_hD\n",
    "ytt_hD['Espèce prédite'] = pd.DataFrame(iris_tt_hat, index=y_test.index)\n",
    "ytt_hD['Espèce observée'] = pd.DataFrame(y_test_species, index=y_test.index)\n",
    "print(f\"{color.BOLD}{color.RED}Test Set{color.OFF}. Comparaison entre espèce prédite et espèce observée.\")\n",
    "pd.set_option('display.max_rows', None) #on veut afficher toutes les lignes des DataFrames\n",
    "pd.options.display.float_format = '{:,.2f}'.format #on formatte les probabilités, sinon c'est illisible\n",
    "display(ytt_hD)\n",
    "pd.set_option('display.max_rows', 10) #reset de l'affichage: 5 premières et 5 dernières lignes\n",
    "pd.options.display.float_format = None #reset de l'affichage: \n",
    "diff_Pred_Obs=np.where(ytt_hD['Espèce prédite'] == ytt_hD['Espèce observée'], 0, 1)\n",
    "print(f\"Nombre d'erreurs : {np.sum(diff_Pred_Obs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55fe30e-ce3d-49bf-b488-6fe9bff3291b",
   "metadata": {},
   "source": [
    "##### **3.** Bilan de la performance du modèle prédictif sous forme de matrice de confusion\n",
    "\n",
    "- Tracer les matrices de confusion du jeu de données d'apprentissage et de celui de test. \n",
    "- Comparer aux résultats de la [partie cours](../DS4B-Iris3.ipynb).\n",
    "- Le modèle a-t-il été amélioré ou bien la connaisssance de la largeur et de la longueur de sépales en plus de celles des pétales n'est-il pas informatif ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "866bd474-9393-4311-b165-0f66d021e221",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x500 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# entrez ci-dessous votre code python\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "\n",
    "cm_labels = dfi['species'].unique()\n",
    "cm_tr = confusion_matrix(np.argmax(y_train.to_numpy(),axis=1), np.argmax(y_train_hat,axis=1))\n",
    "cm_tt = confusion_matrix(np.argmax(y_test.to_numpy(),axis=1), np.argmax(y_test_hat,axis=1))\n",
    "\n",
    "fig=plt.figure(figsize=(12, 5))\n",
    "gs = gridspec.GridSpec(nrows=1, ncols=2, width_ratios=[1, 1])\n",
    "\n",
    "ax00 = fig.add_subplot(gs[0, 0], title=\"Training set. Matrice de confusion\")\n",
    "sns.heatmap(pd.DataFrame(cm_tr, columns=cm_labels, index=cm_labels), ax=ax00, cmap=plt.cm.Blues, annot = True)\n",
    "ax00.set_xlabel(\"prédit\", fontsize = 20)\n",
    "ax00.set_ylabel(\"réel\", fontsize = 20)\n",
    "\n",
    "ax01=fig.add_subplot(gs[0, 1], title=\"Test set. Matrice de confusion\")\n",
    "sns.heatmap(pd.DataFrame(cm_tt, columns=cm_labels, index=cm_labels), ax=ax01, cmap=plt.cm.Blues, annot = True)\n",
    "ax01.set_xlabel(\"prédit\", fontsize = 20)\n",
    "ax01.set_ylabel(\"réel\", fontsize = 20)\n",
    "plt.show()\n",
    "\n",
    "fig.savefig(\"./svg-images/Iris3-ConfusionMatrix-petals-sepals.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0387725f-c6ae-430e-a9b8-d692c8893dae",
   "metadata": {},
   "source": [
    "### Bilan\n",
    "\n",
    "<div class=\"warn\">\n",
    "\n",
    "Si tout s'est bien passé, vous avez trouvé des matrices de confusion proches du résultat ci-dessous :\n",
    "    \n",
    "<p><img width=\"950px\" src=\"./svg-images/Iris3-ConfusionMatrix-petals-sepals-saved.png\" style=\"margin-left:auto; margin-right:auto; display: block;\" id=\"img_MLIris_p\"/></p>  \n",
    "\n",
    "Il y a donc une nette amélioration par rapport à une IA qui a exploité deux descripteurs uniquement :\n",
    "    \n",
    "<p><img width=\"950px\" src=\"../DS4B-svg/Iris3-ConfusionMatrix-petals-saved.png\" style=\"margin-left:auto; margin-right:auto; display: block;\" id=\"img_MLIris_ps\"/></p>  \n",
    "    \n",
    "**<span style=\"color:red\"> Il n'y a pas d'amélioration ?</span>** Pas de chance. Relancez l'algorithme depuis le début\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "af354bcb",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Fin à:** Thursday 03 November 2022, 21:41:43  \n",
       "**Durée:** 00:00:12 452ms"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<p style=\"text-align: center\"><img width=\"800px\" src=\"../config/svg/logoFin.svg\" style=\"margin-left:auto; margin-right:auto\"/></p>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vID.end(cwd0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
